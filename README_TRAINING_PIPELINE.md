# RC Car í•™ìŠµ íŒŒì´í”„ë¼ì¸ í†µí•© ê°€ì´ë“œ

ì´ ë¬¸ì„œëŠ” RC Carë¥¼ ìœ„í•œ ëª¨ë“  í•™ìŠµ ë°©ë²•ì„ í†µí•©í•˜ì—¬ ì •ë¦¬í•œ ê°€ì´ë“œì…ë‹ˆë‹¤.

## ğŸ“‹ ëª©ì°¨

1. [í•™ìŠµ ë°©ë²• ê°œìš”](#í•™ìŠµ-ë°©ë²•-ê°œìš”)
2. [ê¶Œì¥ í•™ìŠµ íŒŒì´í”„ë¼ì¸](#ê¶Œì¥-í•™ìŠµ-íŒŒì´í”„ë¼ì¸)
3. [í•™ìŠµ ë°©ë²•ë³„ ìƒì„¸ ê°€ì´ë“œ](#í•™ìŠµ-ë°©ë²•ë³„-ìƒì„¸-ê°€ì´ë“œ)
4. [ì„œë²„-í´ë¼ì´ì–¸íŠ¸ í•™ìŠµ](#ì„œë²„-í´ë¼ì´ì–¸íŠ¸-í•™ìŠµ)
5. [ì•¡ì…˜ ì •ì˜](#ì•¡ì…˜-ì •ì˜)
6. [ë¬¸ì œ í•´ê²°](#ë¬¸ì œ-í•´ê²°)

---

## í•™ìŠµ ë°©ë²• ê°œìš”

ì´ í”„ë¡œì íŠ¸ëŠ” 5ê°€ì§€ í•™ìŠµ ë°©ë²•ì„ ì§€ì›í•©ë‹ˆë‹¤:

| í•™ìŠµ ë°©ë²• | íŒŒì¼ | ì„¤ëª… | ì‚¬ìš© ì‹œì  |
|---------|------|------|----------|
| **A3C** | `train_a3c.py` | ë¹„ë™ê¸° ê°•í™”í•™ìŠµ, ë©€í‹° í”„ë¡œì„¸ìŠ¤ | ë¹ ë¥¸ ì‚¬ì „ í•™ìŠµ |
| **PPO (CarRacing)** | `train_ppo.py` | PPO ê°•í™”í•™ìŠµ, CarRacing í™˜ê²½ | ì‹œë®¬ë ˆì´ì…˜ ì‚¬ì „ í•™ìŠµ |
| **PPO (ì‹œë®¬ë ˆì´ì…˜)** | `train_ppo.py` | PPO ê°•í™”í•™ìŠµ, Pygame ì‹œë®¬ë ˆì´ì…˜ | í•˜ë“œì›¨ì–´ ì—†ëŠ” í•™ìŠµ |
| **Teacher Forcing** | `train_with_teacher_forcing.py` | ì‚¬ëŒ ë°ëª¨ë¡œ Supervised Learning | ì‹¤ì œ í™˜ê²½ ì‚¬ì „ í•™ìŠµ |
| **Human Feedback** | `train_human_feedback.py` | ì‚¬ëŒ í‰ê°€ ê¸°ë°˜ ê°•í™”í•™ìŠµ | Fine-tuning |
| **Imitation RL** | `train_imitation_rl.py` | ì‚¬ëŒ ë°ëª¨ë¡œ Imitation Learning via RL | ì‹¤ì œ í™˜ê²½ Fine-tuning |

---

## ê¶Œì¥ í•™ìŠµ íŒŒì´í”„ë¼ì¸

### íŒŒì´í”„ë¼ì¸ 1: ì‹œë®¬ë ˆì´ì…˜ ì¤‘ì‹¬ (ê¶Œì¥)

```
1. CarRacing/ì‹œë®¬ë ˆì´ì…˜ PPO ì‚¬ì „ í•™ìŠµ
   â†“
2. ì‚¬ëŒ ë°ëª¨ ë°ì´í„° ìˆ˜ì§‘
   â†“
3. Teacher Forcing (Supervised Learning)
   â†“
4. Imitation RL (ì„ íƒì‚¬í•­)
   â†“
5. Human Feedback (ì„ íƒì‚¬í•­)
   â†“
6. ì¶”ë¡ /í…ŒìŠ¤íŠ¸
```

### íŒŒì´í”„ë¼ì¸ 2: ì‹¤ì œ í™˜ê²½ ì¤‘ì‹¬

```
1. ì‚¬ëŒ ë°ëª¨ ë°ì´í„° ìˆ˜ì§‘
   â†“
2. Teacher Forcing (Supervised Learning)
   â†“
3. Imitation RL
   â†“
4. Human Feedback
   â†“
5. ì¶”ë¡ /í…ŒìŠ¤íŠ¸
```

---

## í•™ìŠµ ë°©ë²•ë³„ ìƒì„¸ ê°€ì´ë“œ

### 1. A3C í•™ìŠµ (ë¹„ë™ê¸° ê°•í™”í•™ìŠµ)

**íŒŒì¼**: `train_a3c.py`

**ì„¤ëª…**: ë©€í‹° í”„ë¡œì„¸ìŠ¤ë¥¼ ì‚¬ìš©í•œ ë¹„ë™ê¸° ê°•í™”í•™ìŠµìœ¼ë¡œ ë¹ ë¥´ê²Œ ì‚¬ì „ í•™ìŠµí•©ë‹ˆë‹¤.

**ì‚¬ìš©ë²•**:

```bash
# A3C í•™ìŠµ ì‹¤í–‰ (CarRacing í™˜ê²½ ì‚¬ìš©)
python train_a3c.py \
    --num-workers 4 \
    --total-steps 500000 \
    --save-path a3c_model_best.pth
```

**ì£¼ìš” íŒŒë¼ë¯¸í„°**:
- `--num-workers`: ì›Œì»¤ í”„ë¡œì„¸ìŠ¤ ìˆ˜ (ê¸°ë³¸: 4)
- `--total-steps`: ì´ í•™ìŠµ ìŠ¤í… ìˆ˜ (ê¸°ë³¸: 1000000)
- `--save-path`: ëª¨ë¸ ì €ì¥ ê²½ë¡œ (ê¸°ë³¸: `a3c_model.pth`)
- `--max-episode-steps`: ì—í”¼ì†Œë“œ ìµœëŒ€ ê¸¸ì´ (ê¸°ë³¸: 1000)
- `--hidden-dim`: íˆë“  ë ˆì´ì–´ ì°¨ì› (ê¸°ë³¸: 256)
- `--lr-actor`: Actor í•™ìŠµë¥  (ê¸°ë³¸: 3e-4)
- `--lr-critic`: Critic í•™ìŠµë¥  (ê¸°ë³¸: 3e-4)

**íŠ¹ì§•**:
- ë©€í‹° í”„ë¡œì„¸ìŠ¤ë¡œ ë¹ ë¥¸ í•™ìŠµ (CarRacing í™˜ê²½ ì‚¬ìš©)
- ì‹¤ì œ í•˜ë“œì›¨ì–´ ì—†ì´ ì‹¤í–‰ ê°€ëŠ¥
- ì›Œì»¤ ìˆ˜ ì¡°ì •ìœ¼ë¡œ í•™ìŠµ ì†ë„ ì œì–´ ê°€ëŠ¥

---

### 2. PPO í•™ìŠµ (CarRacing/ì‹œë®¬ë ˆì´ì…˜)

**íŒŒì¼**: `train_ppo.py`

**ì„¤ëª…**: CarRacing ë˜ëŠ” Pygame ì‹œë®¬ë ˆì´ì…˜ í™˜ê²½ì—ì„œ PPO ê°•í™”í•™ìŠµì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

#### 2-1. CarRacing í™˜ê²½

```bash
# CarRacing í™˜ê²½ì—ì„œ í•™ìŠµ
python train_ppo.py \
    --env-type carracing \
    --total-steps 500000 \
    --save-path ppo_carracing.pth \
    --render  # ì‹œê°í™” (ì„ íƒì‚¬í•­)
```

#### 2-2. ì‹œë®¬ë ˆì´ì…˜ í™˜ê²½

```bash
# Pygame ì‹œë®¬ë ˆì´ì…˜ì—ì„œ í•™ìŠµ
python train_ppo.py \
    --env-type sim \
    --total-steps 200000 \
    --save-path ppo_sim.pth
```

**ì£¼ìš” íŒŒë¼ë¯¸í„°**:
- `--env-type`: `carracing` ë˜ëŠ” `sim`
- `--total-steps`: ì´ í•™ìŠµ ìŠ¤í… ìˆ˜ (ê¸°ë³¸: 100000)
- `--max-episode-steps`: ì—í”¼ì†Œë“œ ìµœëŒ€ ê¸¸ì´ (ê¸°ë³¸: 1000)
- `--update-frequency`: PPO ì—…ë°ì´íŠ¸ ì£¼ê¸° (ê¸°ë³¸: 2048)
- `--update-epochs`: ì—…ë°ì´íŠ¸ ì—í­ ìˆ˜ (ê¸°ë³¸: 10)
- `--hidden-dim`: íˆë“  ë ˆì´ì–´ ì°¨ì› (ê¸°ë³¸: 256)
- `--lr-actor`: Actor í•™ìŠµë¥  (ê¸°ë³¸: 3e-4)
- `--lr-critic`: Critic í•™ìŠµë¥  (ê¸°ë³¸: 3e-4)
- `--render`: ì‹œê°í™” í™œì„±í™”

**íŠ¹ì§•**:
- ì‹¤ì œ í•˜ë“œì›¨ì–´ ì—†ì´ ë¹ ë¥¸ í•™ìŠµ
- CarRacingì€ RC Carì™€ ìœ ì‚¬í•œ ë„ë©”ì¸
- ì‚¬ì „í•™ìŠµëœ ëª¨ë¸ ì „ì´ ê°€ëŠ¥

**âš ï¸ ì£¼ì˜**: ì‹¤ì œ í•˜ë“œì›¨ì–´ì—ì„œ ì§ì ‘ í•™ìŠµí•˜ì§€ ë§ˆì„¸ìš”! ì‹œë®¬ë ˆì´ì…˜ì—ì„œ ë¨¼ì € í•™ìŠµ í›„ ì „ì´í•˜ì„¸ìš”.

---

### 3. ì‚¬ëŒ ë°ëª¨ ë°ì´í„° ìˆ˜ì§‘

**íŒŒì¼**: `collect_human_demonstrations.py`

**ì„¤ëª…**: ì‚¬ëŒì´ ì§ì ‘ RC Carë¥¼ ì¡°ì‘í•œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.

**ì‚¬ìš©ë²•**:

```bash
# ì‹¤ì œ í•˜ë“œì›¨ì–´ì—ì„œ ë°ì´í„° ìˆ˜ì§‘
python collect_human_demonstrations.py \
    --env-type real \
    --port /dev/ttyACM0 \
    --episodes 5 \
    --output human_demos.pkl
```

**í‚¤ë³´ë“œ ì¡°ì‘**:
- `w`: ì „ì§„ (Action 3)
- `a`: ì¢ŒíšŒì „ + ê°€ìŠ¤ (Action 2)
- `d`: ìš°íšŒì „ + ê°€ìŠ¤ (Action 1)
- `s`: ì •ì§€ (Action 0)
- `x`: ë¸Œë ˆì´í¬ (Action 4)
- `q`: ì—í”¼ì†Œë“œ ì¢…ë£Œ

**ìˆ˜ì§‘ë˜ëŠ” ë°ì´í„°**:
```python
{
    'metadata': {
        'env_type': 'real',
        'num_episodes': 5,
        'total_steps': 250
    },
    'demonstrations': [
        {
            'states': [...],      # 16x16 grayscale ì´ë¯¸ì§€
            'actions': [...],     # ì´ì‚° ì•¡ì…˜ (0-4)
            'rewards': [...],     # í™˜ê²½ ë¦¬ì›Œë“œ
            'dones': [...],       # ì¢…ë£Œ í”Œë˜ê·¸
            'timestamps': [...]   # íƒ€ì„ìŠ¤íƒ¬í”„
        },
        ...
    ]
}
```

**íŠ¹ì§•**:
- ì‹¤ì œ í™˜ê²½ì—ì„œ ì „ë¬¸ê°€ í–‰ë™ í•™ìŠµ
- Teacher Forcing ë° Imitation RLì— ì‚¬ìš©
- ì—¬ëŸ¬ ì—í”¼ì†Œë“œ ìˆ˜ì§‘ ê°€ëŠ¥

---

### 4. Teacher Forcing (Supervised Learning)

**íŒŒì¼**: `train_with_teacher_forcing.py`

**ì„¤ëª…**: ì‚¬ëŒì´ ì¡°ì‘í•œ (ìƒíƒœ, ì•¡ì…˜) ìŒìœ¼ë¡œ Maximum Likelihood Estimationì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

**ì‚¬ìš©ë²•**:

```bash
# Supervised Learning ì‚¬ì „ í•™ìŠµ
python train_with_teacher_forcing.py \
    --demos human_demos.pkl \
    --pretrain-epochs 100 \
    --pretrain-save pretrained_model.pth

# ì‚¬ì „ í•™ìŠµ í›„ ê°•í™”í•™ìŠµ Fine-tuning
python train_with_teacher_forcing.py \
    --demos human_demos.pkl \
    --pretrain-epochs 100 \
    --pretrain-save pretrained_model.pth \
    --rl-steps 100000 \
    --rl-save fine_tuned_model.pth
```

**ì£¼ìš” íŒŒë¼ë¯¸í„°**:
- `--demos`: ë°ëª¨ ë°ì´í„° íŒŒì¼ ê²½ë¡œ
- `--pretrain-epochs`: ì‚¬ì „ í•™ìŠµ ì—í­ ìˆ˜ (ê¸°ë³¸: 100)
- `--pretrain-save`: ì‚¬ì „ í•™ìŠµ ëª¨ë¸ ì €ì¥ ê²½ë¡œ
- `--rl-steps`: ê°•í™”í•™ìŠµ Fine-tuning ìŠ¤í… ìˆ˜ (ì„ íƒì‚¬í•­)
- `--rl-save`: Fine-tuning ëª¨ë¸ ì €ì¥ ê²½ë¡œ

**íŠ¹ì§•**:
- ì‚¬ëŒì˜ í–‰ë™ íŒ¨í„´ ì§ì ‘ í•™ìŠµ
- ë¹ ë¥¸ ìˆ˜ë ´ (Supervised Learning)
- ê°•í™”í•™ìŠµ Fine-tuning ê°€ëŠ¥

---

### 5. Imitation RL (Imitation Learning via Reinforcement Learning)

**íŒŒì¼**: `train_imitation_rl.py`

**ì„¤ëª…**: ì‚¬ëŒ ë°ëª¨ ë°ì´í„°ì™€ì˜ ì¼ì¹˜ìœ¨ì„ ë¦¬ì›Œë“œë¡œ ì‚¬ìš©í•˜ì—¬ PPO ê°•í™”í•™ìŠµì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

**ì‚¬ìš©ë²•**:

```bash
# Imitation RL í•™ìŠµ
python train_imitation_rl.py \
    --demos human_demos.pkl \
    --model a3c_model_best.pth \  # ì‚¬ì „ í•™ìŠµ ëª¨ë¸ (ì„ íƒì‚¬í•­)
    --epochs 20 \
    --batch-size 64 \
    --learning-rate 3e-4 \
    --save imitation_rl_model.pth
```

**ì„œë²„ APIë¥¼ í†µí•œ í•™ìŠµ**:

```bash
# í´ë¼ì´ì–¸íŠ¸ì—ì„œ í•™ìŠµ ìš”ì²­
python client_upload.py \
    --server http://SERVER_IP:5000 \
    --train uploaded_data/demos_XXX.pkl \
    --epochs 20 \
    --batch-size 64 \
    --learning-rate 3e-4
```

**ì£¼ìš” íŒŒë¼ë¯¸í„°**:
- `--demos`: ë°ëª¨ ë°ì´í„° íŒŒì¼ ê²½ë¡œ (í•„ìˆ˜)
- `--model`: ì‚¬ì „ í•™ìŠµ ëª¨ë¸ ê²½ë¡œ (ì„ íƒì‚¬í•­)
- `--epochs`: í•™ìŠµ ì—í­ ìˆ˜ (ê¸°ë³¸: 100)
- `--batch-size`: ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸: 64)
- `--learning-rate`: í•™ìŠµë¥  (ê¸°ë³¸: 3e-4)
- `--save`: ëª¨ë¸ ì €ì¥ ê²½ë¡œ (ê¸°ë³¸: `imitation_rl_model.pth`)
- `--device`: ë””ë°”ì´ìŠ¤ (ê¸°ë³¸: `cpu`)

**ë¦¬ì›Œë“œ ì •ì˜**:
- ì•¡ì…˜ ì¼ì¹˜: `+1.0`
- ì•¡ì…˜ ë¶ˆì¼ì¹˜: `-0.1`

**íŠ¹ì§•**:
- Supervised Learningê³¼ Reinforcement Learning ê²°í•©
- ì‹œí€€ìŠ¤ ëª¨ë“œ ì§€ì› (ì—í”¼ì†Œë“œë³„ í•™ìŠµ)
- Recurrent ëª¨ë¸ ì§€ì› (Deep Supervision)
- ì—í”¼ì†Œë“œë³„ ì¼ì¹˜ìœ¨ ê³„ì‚°

**ë¦¬ì›Œë“œ ì‚¬ìš©**: Imitation Learningì´ë¯€ë¡œ í™˜ê²½ì˜ `rewards`ëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ëª¨ë¸ ì•¡ì…˜ê³¼ ì „ë¬¸ê°€ ì•¡ì…˜ì˜ ì¼ì¹˜ìœ¨ë¡œ ë¦¬ì›Œë“œë¥¼ ìë™ ìƒì„±í•©ë‹ˆë‹¤.

---

### 6. Human Feedback (ì‚¬ëŒ í‰ê°€ ê¸°ë°˜ ê°•í™”í•™ìŠµ)

**íŒŒì¼**: `train_human_feedback.py`

**ì„¤ëª…**: ì‚¬ëŒì´ ëª¨ë¸ì˜ ì£¼í–‰ì„ í‰ê°€í•˜ì—¬ ë¦¬ì›Œë“œë¥¼ ìƒì„±í•˜ê³  ê°•í™”í•™ìŠµì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

**ì‚¬ìš©ë²•**:

```bash
# Human Feedback í•™ìŠµ
python train_human_feedback.py \
    --model pretrained_model.pth \
    --port /dev/ttyACM0 \
    --num-episodes 10 \
    --save-path ppo_feedback_model.pth
```

**ì‚¬ìš© ë°©ë²•**:
1. ëª¨ë¸ì´ ìë™ìœ¼ë¡œ ì£¼í–‰
2. ì‚¬ëŒì´ 0.0~1.0 ì ìˆ˜ë¡œ í‰ê°€
3. í‰ê°€ ì ìˆ˜ë¥¼ ë¦¬ì›Œë“œë¡œ ë³€í™˜í•˜ì—¬ í•™ìŠµ
4. ë°˜ë³µ

**ì£¼ìš” íŒŒë¼ë¯¸í„°**:
- `--model`: ì‚¬ì „ í•™ìŠµ ëª¨ë¸ ê²½ë¡œ
- `--port`: ì‹œë¦¬ì–¼ í¬íŠ¸ (ì‹¤ì œ í•˜ë“œì›¨ì–´ ì‚¬ìš© ì‹œ)
- `--num-episodes`: ì—í”¼ì†Œë“œ ìˆ˜
- `--save-path`: ëª¨ë¸ ì €ì¥ ê²½ë¡œ

**íŠ¹ì§•**:
- ì‚¬ëŒì˜ ì£¼ê´€ì  í‰ê°€ í™œìš©
- ì‹¤ì œ í™˜ê²½ì—ì„œ ì§ì ‘ í•™ìŠµ
- Fine-tuningì— ì í•©

---

## ì„œë²„-í´ë¼ì´ì–¸íŠ¸ í•™ìŠµ

ì„œë²„-í´ë¼ì´ì–¸íŠ¸ ì•„í‚¤í…ì²˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¼ì¦ˆë² ë¦¬ íŒŒì´ì—ì„œ ë°ì´í„° ìˆ˜ì§‘/ì¶”ë¡ ë§Œ ìˆ˜í–‰í•˜ê³ , í•™ìŠµì€ GPU ì„œë²„ì—ì„œ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**ì•„í‚¤í…ì²˜**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         HTTP REST API         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ë¼ì¦ˆë² ë¦¬ íŒŒì´    â”‚ â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚   ì„œë²„ (GPU)     â”‚
â”‚  (í´ë¼ì´ì–¸íŠ¸)     â”‚                               â”‚   (í•™ìŠµ ì„œë²„)    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                               â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ - ì¹´ë©”ë¼ ìˆ˜ì§‘     â”‚                               â”‚ - ë°ì´í„° ìˆ˜ì‹     â”‚
â”‚ - í•˜ë“œì›¨ì–´ ì œì–´   â”‚                               â”‚ - ëª¨ë¸ í•™ìŠµ      â”‚
â”‚ - ì¶”ë¡  ì‹¤í–‰       â”‚                               â”‚ - ëª¨ë¸ ì €ì¥      â”‚
â”‚ - ë°ì´í„° ì „ì†¡     â”‚                               â”‚ - ëª¨ë¸ ì œê³µ      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ì„œë²„ ì„¤ì •

```bash
# ì„œë²„ ì‹¤í–‰
python server_api.py --host 0.0.0.0 --port 5000
```

### ì „ì²´ ì›Œí¬í”Œë¡œìš°

```bash
# 1. ì„œë²„ ì‹œì‘ (GPU ì„œë²„)
python server_api.py --host 0.0.0.0 --port 5000

# 2. ë°ì´í„° ìˆ˜ì§‘ (ë¼ì¦ˆë² ë¦¬ íŒŒì´)
python collect_human_demonstrations.py --env-type real --episodes 5

# 3. ë°ì´í„° ì—…ë¡œë“œ (ë¼ì¦ˆë² ë¦¬ íŒŒì´)
python client_upload.py --server http://SERVER_IP:5000 --upload human_demos.pkl

# 4. í•™ìŠµ ìš”ì²­ (ë¼ì¦ˆë² ë¦¬ íŒŒì´ ë˜ëŠ” ì„œë²„)
python client_upload.py \
    --server http://SERVER_IP:5000 \
    --train uploaded_data/demos_XXX.pkl \
    --epochs 20 \
    --batch-size 64 \
    --learning-rate 3e-4

# 5. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (ë¼ì¦ˆë² ë¦¬ íŒŒì´)
python client_upload.py --server http://SERVER_IP:5000 --download latest_model.pth

# 6. ì¶”ë¡  ì‹¤í–‰ (ë¼ì¦ˆë² ë¦¬ íŒŒì´)
python run_ai_agent.py --model latest_model.pth --env-type real
```

ì„œë²„ API ìì„¸í•œ ë‚´ìš©ì€ `server_api.py` ì½”ë“œ ì°¸ê³ .

---

## ì•¡ì…˜ ì •ì˜

ì´ í”„ë¡œì íŠ¸ëŠ” **ì´ì‚° ì•¡ì…˜**ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤:

| ì•¡ì…˜ ID | ì„¤ëª… | RC Car ë™ì‘ |
|--------|------|------------|
| **0** | ì •ì§€ (Stop/Coast) | ëª¨í„° ì •ì§€ |
| **1** | ìš°íšŒì „ + ê°€ìŠ¤ (Right + Gas) | ìš°ì¸¡ ëª¨í„° ëŠë¦¬ê²Œ, ì¢Œì¸¡ ëª¨í„° ë¹ ë¥´ê²Œ |
| **2** | ì¢ŒíšŒì „ + ê°€ìŠ¤ (Left + Gas) | ì¢Œì¸¡ ëª¨í„° ëŠë¦¬ê²Œ, ìš°ì¸¡ ëª¨í„° ë¹ ë¥´ê²Œ |
| **3** | ì§ì§„ ê°€ìŠ¤ (Gas/Forward) | ì–‘ìª½ ëª¨í„° ë™ì¼ ì†ë„ ì „ì§„ |
| **4** | ë¸Œë ˆì´í¬ (Brake) | ê¸‰ì •ì§€ |

---

## ì „ì²´ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì˜ˆì‹œ

### ì˜ˆì‹œ 1: ì‹œë®¬ë ˆì´ì…˜ ì¤‘ì‹¬ (ê¶Œì¥)

```bash
# 1ë‹¨ê³„: CarRacing í™˜ê²½ì—ì„œ ì‚¬ì „ í•™ìŠµ
python train_ppo.py \
    --env-type carracing \
    --total-steps 500000 \
    --save-path ppo_carracing.pth

# 2ë‹¨ê³„: ì‚¬ëŒ ë°ëª¨ ë°ì´í„° ìˆ˜ì§‘
python collect_human_demonstrations.py \
    --env-type real \
    --port /dev/ttyACM0 \
    --episodes 5 \
    --output human_demos.pkl

# 3ë‹¨ê³„: Teacher Forcing ì‚¬ì „ í•™ìŠµ
python train_with_teacher_forcing.py \
    --demos human_demos.pkl \
    --pretrain-epochs 100 \
    --pretrain-save pretrained_model.pth

# 4ë‹¨ê³„: Imitation RL Fine-tuning
python train_imitation_rl.py \
    --demos human_demos.pkl \
    --model pretrained_model.pth \
    --epochs 20 \
    --save imitation_rl_model.pth

# 5ë‹¨ê³„: ì¶”ë¡ /í…ŒìŠ¤íŠ¸
python run_ai_agent.py \
    --model imitation_rl_model.pth \
    --env-type real \
    --port /dev/ttyACM0
```

### ì˜ˆì‹œ 2: ì‹¤ì œ í™˜ê²½ ì¤‘ì‹¬

```bash
# 1ë‹¨ê³„: ì‚¬ëŒ ë°ëª¨ ë°ì´í„° ìˆ˜ì§‘
python collect_human_demonstrations.py \
    --env-type real \
    --port /dev/ttyACM0 \
    --episodes 10 \
    --output human_demos.pkl

# 2ë‹¨ê³„: Teacher Forcing ì‚¬ì „ í•™ìŠµ
python train_with_teacher_forcing.py \
    --demos human_demos.pkl \
    --pretrain-epochs 100 \
    --pretrain-save pretrained_model.pth

# 3ë‹¨ê³„: Imitation RL
python train_imitation_rl.py \
    --demos human_demos.pkl \
    --model pretrained_model.pth \
    --epochs 20 \
    --save imitation_rl_model.pth

# 4ë‹¨ê³„: Human Feedback (ì„ íƒì‚¬í•­)
python train_human_feedback.py \
    --model imitation_rl_model.pth \
    --port /dev/ttyACM0 \
    --num-episodes 10 \
    --save-path final_model.pth

# 5ë‹¨ê³„: ì¶”ë¡ /í…ŒìŠ¤íŠ¸
python run_ai_agent.py \
    --model final_model.pth \
    --env-type real \
    --port /dev/ttyACM0
```

### ì˜ˆì‹œ 3: ì„œë²„-í´ë¼ì´ì–¸íŠ¸ ë°©ì‹

```bash
# ì„œë²„ì—ì„œ
python server_api.py --host 0.0.0.0 --port 5000

# í´ë¼ì´ì–¸íŠ¸ì—ì„œ (ë¼ì¦ˆë² ë¦¬ íŒŒì´)
# 1. ë°ì´í„° ìˆ˜ì§‘
python collect_human_demonstrations.py --env-type real --episodes 5

# 2. ë°ì´í„° ì—…ë¡œë“œ
python client_upload.py \
    --server http://SERVER_IP:5000 \
    --upload human_demos.pkl

# 3. í•™ìŠµ ìš”ì²­
python client_upload.py \
    --server http://SERVER_IP:5000 \
    --train uploaded_data/demos_XXX.pkl \
    --epochs 20 \
    --batch-size 64 \
    --learning-rate 3e-4

# 4. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
python client_upload.py \
    --server http://SERVER_IP:5000 \
    --download imitation_rl_model.pth

# 5. ì¶”ë¡ 
python run_ai_agent.py \
    --model imitation_rl_model.pth \
    --env-type real
```

---

## ë¬¸ì œ í•´ê²°

### ë°ì´í„° í•„í„°ë§

`train_imitation_rl.py`ëŠ” ìë™ìœ¼ë¡œ ìœ íš¨í•˜ì§€ ì•Šì€ ì—í”¼ì†Œë“œë¥¼ í•„í„°ë§í•©ë‹ˆë‹¤:
- `states`ë‚˜ `actions`ê°€ ì—†ëŠ” ì—í”¼ì†Œë“œ
- ë¹ˆ ì—í”¼ì†Œë“œ
- í•„í„°ë§ëœ ì—í”¼ì†Œë“œ ìˆ˜ê°€ ì¶œë ¥ë©ë‹ˆë‹¤

### ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨

- ëª¨ë¸ íŒŒì¼ ê²½ë¡œ í™•ì¸
- ëª¨ë¸ê³¼ ì—ì´ì „íŠ¸ì˜ `state_dim` ì¼ì¹˜ í™•ì¸ (ìë™ ê°ì§€ë¨)
- ì‚¬ì „ í•™ìŠµ ëª¨ë¸ì€ `--model` íŒŒë¼ë¯¸í„°ë¡œ ì§€ì • (ê¸°ë³¸ê°’ ì—†ìŒ)

### í•™ìŠµ ì†ë„ê°€ ëŠë¦´ ë•Œ

- GPU ì‚¬ìš© í™•ì¸
- ë°°ì¹˜ í¬ê¸° ì¡°ì •
- ë Œë”ë§ ë¹„í™œì„±í™”
- ì„œë²„-í´ë¼ì´ì–¸íŠ¸ ë°©ì‹ ì‚¬ìš© (GPU ì„œë²„ í™œìš©)

### ë©”ëª¨ë¦¬ ë¶€ì¡±

- ë°°ì¹˜ í¬ê¸° ê°ì†Œ (`--batch-size 32`)
- ì—í”¼ì†Œë“œ ê¸¸ì´ ì œí•œ
- ì—…ë°ì´íŠ¸ ì£¼ê¸° ê°ì†Œ (`--update-frequency 1024`)

### ì¼ì¹˜ìœ¨ì´ ë‚®ì„ ë•Œ

- ë” ë§ì€ ë°ëª¨ ë°ì´í„° ìˆ˜ì§‘
- ë” ë§ì€ ì—í­ í•™ìŠµ
- í•™ìŠµë¥  ì¡°ì •
- Teacher Forcingìœ¼ë¡œ ì‚¬ì „ í•™ìŠµ í›„ Imitation RL

---

## ì°¸ê³  ë¬¸ì„œ

- `README.md`: ì „ì²´ í”„ë¡œì íŠ¸ ê°œìš” ë° í•˜ë“œì›¨ì–´ ì„¤ì •

---

## í•™ìŠµ ë°©ë²• ë¹„êµ

| ë°©ë²• | í•™ìŠµ ì†ë„ | ë°ì´í„° í•„ìš” | ì‹¤ì œ í™˜ê²½ í•„ìš” | Fine-tuning | ì¶”ì²œë„ |
|-----|---------|-----------|--------------|------------|--------|
| **A3C** | ë§¤ìš° ë¹ ë¦„ | âŒ | âŒ | âš ï¸ | â­â­â­â­ |
| **PPO (CarRacing)** | ë¹ ë¦„ | âŒ | âŒ | âœ… | â­â­â­â­â­ |
| **PPO (Sim)** | ë¹ ë¦„ | âŒ | âŒ | âœ… | â­â­â­â­ |
| **Teacher Forcing** | ë§¤ìš° ë¹ ë¦„ | âœ… | âœ… | âœ… | â­â­â­â­â­ |
| **Imitation RL** | ë³´í†µ | âœ… | âŒ* | âœ… | â­â­â­â­â­ |
| **Human Feedback** | ëŠë¦¼ | âŒ | âœ… | âœ… | â­â­â­ |

\* ì„œë²„-í´ë¼ì´ì–¸íŠ¸ ë°©ì‹ ì‚¬ìš© ì‹œ ì‹¤ì œ í™˜ê²½ ë¶ˆí•„ìš”

**ê¶Œì¥ ìˆœì„œ**: PPO (CarRacing) â†’ Teacher Forcing â†’ Imitation RL â†’ Human Feedback

---

ì´ ê°€ì´ë“œë¥¼ ë”°ë¼í•˜ë©´ íš¨ê³¼ì ìœ¼ë¡œ RC Carë¥¼ í•™ìŠµì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤! ğŸš—

