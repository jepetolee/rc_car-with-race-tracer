#!/usr/bin/env python3
"""
AI ì—ì´ì „íŠ¸ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
í•™ìŠµëœ TRM-DQN ëª¨ë¸ì„ ë¡œë“œí•˜ì—¬ RC Carë¥¼ ì œì–´

QR ì½”ë“œ ê°ì§€ ê¸°ëŠ¥:
    - ì‹¤ì œ í•˜ë“œì›¨ì–´ í™˜ê²½(--env-type real)ì—ì„œ ìë™ í™œì„±í™”
    - QR ì½”ë“œ ê°ì§€ ì‹œ ì°¨ëŸ‰ì´ 4ì´ˆê°„ ìë™ ì •ì§€
    - CNN ëª¨ë¸ ì‚¬ìš© ì‹œ ë” ì •í™•í•œ ê°ì§€ (--qr-cnn-model ì˜µì…˜)
    - CNN ëª¨ë¸ ë¯¸ì§€ì • ì‹œ OpenCV ê¸°ë³¸ ê°ì§€ê¸° ì‚¬ìš©

ì‚¬ìš©ë²•:
    python run_ai_agent.py --model ppo_model.pth --port /dev/ttyACM0 --delay 0.1
    python run_ai_agent.py --model ppo_model.pth --env-type real --episodes 5
    python run_ai_agent.py --model ppo_model.pth --env-type real --qr-cnn-model trained_models/qr_cnn_best.pth
"""

import os
# NumPy/PyTorch ì„í¬íŠ¸ ì „ì— í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (Bus error ë°©ì§€)
os.environ['OPENBLAS_NUM_THREADS'] = '1'
os.environ['MKL_NUM_THREADS'] = '1'
os.environ['NUMEXPR_NUM_THREADS'] = '1'
os.environ['OMP_NUM_THREADS'] = '1'
# PyTorch ìŠ¤ë ˆë“œ ì œí•œ
os.environ['TORCH_NUM_THREADS'] = '1'
os.environ['MKL_NUM_THREADS'] = '1'

import argparse
import numpy as np

# PyTorch ì„í¬íŠ¸ (ì•ˆì „í•˜ê²Œ)
print("PyTorch ì„í¬íŠ¸ ì¤‘...", flush=True)
try:
    import torch
    print(f"âœ… PyTorch {torch.__version__} ì„í¬íŠ¸ ì„±ê³µ", flush=True)
except Exception as e:
    print(f"âŒ PyTorch ì„í¬íŠ¸ ì‹¤íŒ¨: {e}", flush=True)
    print("ë¼ì¦ˆë² ë¦¬ íŒŒì´ìš© PyTorchë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”:", flush=True)
    print("  pip install torch --index-url https://download.pytorch.org/whl/cpu", flush=True)
    import sys
    sys.exit(1)
import time
import sys
import os
from datetime import datetime

# í™˜ê²½ ë° ì—ì´ì „íŠ¸ ì„í¬íŠ¸
from rc_car_sim_env import RCCarSimEnv
from car_racing_env import CarRacingEnvWrapper
from ppo_agent import DQNAgent
from rc_car_controller import RCCarController

# ì‹¤ì œ í•˜ë“œì›¨ì–´ í™˜ê²½ì€ ì„ íƒì  ì„í¬íŠ¸
try:
    from rc_car_env import RCCarEnv
    HAS_REAL_ENV = True
except ImportError:
    HAS_REAL_ENV = False
    RCCarEnv = None


class AIAgentRunner:
    """
    AI ì—ì´ì „íŠ¸ ì‹¤í–‰ í´ë˜ìŠ¤
    0.1ì´ˆ ê°„ê²©ìœ¼ë¡œ ì•¡ì…˜ì„ ì‹¤í–‰í•˜ë©° RC Carë¥¼ ì œì–´
    """
    
    def __init__(
        self,
        model_path: str,
        env_type: str = 'carracing',
        port: str = '/dev/ttyACM0',
        action_delay: float = 0.1,
        max_steps: int = 1000,
        use_discrete_actions: bool = True,  # ì´ì‚° ì•¡ì…˜ë§Œ ì‚¬ìš©
        use_extended_actions: bool = True,
        device: str = None,
        qr_cnn_model_path: str = None
    ):
        """
        Args:
            model_path: í•™ìŠµëœ ëª¨ë¸ ê²½ë¡œ
            env_type: í™˜ê²½ íƒ€ì… ('carracing', 'sim', 'real')
            port: ì‹œë¦¬ì–¼ í¬íŠ¸ (ì‹¤ì œ í•˜ë“œì›¨ì–´ ì‚¬ìš© ì‹œ)
            action_delay: ì•¡ì…˜ ê°„ ì§€ì—° ì‹œê°„ (ì´ˆ, ê¸°ë³¸: 0.1)
            max_steps: ìµœëŒ€ ìŠ¤í… ìˆ˜
            use_discrete_actions: ì´ì‚° ì•¡ì…˜ ì‚¬ìš© ì—¬ë¶€
            use_extended_actions: í™•ì¥ëœ ì•¡ì…˜ ê³µê°„ ì‚¬ìš© ì—¬ë¶€
            device: ë””ë°”ì´ìŠ¤ (cuda/cpu)
            qr_cnn_model_path: QR CNN ëª¨ë¸ ê²½ë¡œ (Noneì´ë©´ OpenCV ì‚¬ìš©)
        """
        self.model_path = model_path
        self.env_type = env_type
        self.port = port
        self.action_delay = action_delay
        self.max_steps = max_steps
        self.use_discrete_actions = use_discrete_actions
        self.use_extended_actions = use_extended_actions
        
        # ë””ë°”ì´ìŠ¤ ì„¤ì • (ë¼ì¦ˆë² ë¦¬ íŒŒì´ì—ì„œëŠ” í•­ìƒ CPU)
        if device is None:
            # ë¼ì¦ˆë² ë¦¬ íŒŒì´ì—ì„œëŠ” GPUê°€ ì—†ìœ¼ë¯€ë¡œ í•­ìƒ CPU ì‚¬ìš©
            self.device = 'cpu'
        else:
            self.device = device
        
        print(f"ğŸ”§ ë””ë°”ì´ìŠ¤: {self.device}")
        print(f"ì•¡ì…˜ ì§€ì—° ì‹œê°„: {action_delay:.3f}ì´ˆ")
        print(f"í™˜ê²½ íƒ€ì…: {env_type}")
        
        # ë‹¨ê³„ë³„ ì´ˆê¸°í™” (Bus error ë°©ì§€)
        print("\n[ì´ˆê¸°í™” ë‹¨ê³„ 1/4] í™˜ê²½ ìƒì„± ì¤‘...")
        try:
            self.env = self._create_env()
            print("âœ… í™˜ê²½ ìƒì„± ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ í™˜ê²½ ìƒì„± ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            raise
        
        # í•˜ë“œì›¨ì–´ ì œì–´ê¸° ìƒì„± (real ëª¨ë“œì¼ ë•Œë§Œ)
        print("\n[ì´ˆê¸°í™” ë‹¨ê³„ 2/4] í•˜ë“œì›¨ì–´ ì œì–´ê¸° ì—°ê²° ì¤‘...")
        self.controller = None
        if env_type == 'real':
            try:
                self.controller = RCCarController(port=port, delay=action_delay)
                print(f"âœ… ì‹¤ì œ í•˜ë“œì›¨ì–´ ì—°ê²°: {port}")
            except Exception as e:
                print(f"âš ï¸  ì‹¤ì œ í•˜ë“œì›¨ì–´ ì—°ê²° ì‹¤íŒ¨: {e}")
                print("ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
                self.env_type = 'sim'
                self.env = self._create_env()
        
        # ì—ì´ì „íŠ¸ ìƒì„± ë° ëª¨ë¸ ë¡œë“œ
        print("\n[ì´ˆê¸°í™” ë‹¨ê³„ 3/4] ì—ì´ì „íŠ¸ ìƒì„± ì¤‘...")
        try:
            self.agent = self._load_agent()
            print("âœ… ì—ì´ì „íŠ¸ ìƒì„± ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ ì—ì´ì „íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            raise
        
        # QR CNN ëª¨ë¸ ë¡œë“œ (ì˜µì…˜)
        print("\n[ì´ˆê¸°í™” ë‹¨ê³„ 4/5] QR CNN ëª¨ë¸ ë¡œë“œ ì¤‘...")
        self.qr_cnn_detector = None
        if qr_cnn_model_path:
            # íŒŒì¼ ê²½ë¡œ í™•ì¸ (ìƒëŒ€ ê²½ë¡œ, ì ˆëŒ€ ê²½ë¡œ ëª¨ë‘ í™•ì¸)
            qr_model_file = qr_cnn_model_path
            if not os.path.isabs(qr_model_file):
                # ìƒëŒ€ ê²½ë¡œì¸ ê²½ìš° ì—¬ëŸ¬ ê°€ëŠ¥í•œ ê²½ë¡œ í™•ì¸
                possible_paths = [
                    qr_model_file,  # í˜„ì¬ ë””ë ‰í† ë¦¬ ê¸°ì¤€
                    os.path.join('.', qr_model_file),  # í˜„ì¬ ë””ë ‰í† ë¦¬ ëª…ì‹œ
                    os.path.join('trained_models', qr_model_file),  # trained_models í´ë”
                    os.path.join('trained_models', os.path.basename(qr_model_file)),  # íŒŒì¼ëª…ë§Œ ì‚¬ìš©
                ]
                
                found = False
                for candidate in possible_paths:
                    if os.path.exists(candidate):
                        qr_model_file = candidate
                        found = True
                        break
                
                if not found:
                    print(f"âš ï¸  QR CNN ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {qr_cnn_model_path}")
                    print(f"   ì‹œë„í•œ ê²½ë¡œë“¤:")
                    for p in possible_paths:
                        print(f"     - {p} ({'ì¡´ì¬' if os.path.exists(p) else 'ì—†ìŒ'})")
                    print("   OpenCV ê¸°ë³¸ QR ê°ì§€ê¸°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                else:
                    # íŒŒì¼ì´ ì¡´ì¬í•˜ë©´ ë¡œë“œ ì‹œë„
                    try:
                        from detect_qr_with_cnn import QRCNNDetector
                        # deviceë¥¼ torch.device ê°ì²´ë¡œ ë³€í™˜
                        qr_device = torch.device(self.device) if isinstance(self.device, str) else self.device
                        self.qr_cnn_detector = QRCNNDetector(qr_model_file, device=qr_device)
                        print(f"âœ… QR CNN ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {qr_model_file}")
                    except Exception as e:
                        print(f"âš ï¸  QR CNN ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
                        print(f"   íŒŒì¼ì€ ì¡´ì¬í•˜ì§€ë§Œ QR CNN ëª¨ë¸ í˜•ì‹ì´ ì•„ë‹ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                        print("   OpenCV ê¸°ë³¸ QR ê°ì§€ê¸°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            else:
                # ì ˆëŒ€ ê²½ë¡œì¸ ê²½ìš°
                if os.path.exists(qr_model_file):
                    try:
                        from detect_qr_with_cnn import QRCNNDetector
                        qr_device = torch.device(self.device) if isinstance(self.device, str) else self.device
                        self.qr_cnn_detector = QRCNNDetector(qr_model_file, device=qr_device)
                        print(f"âœ… QR CNN ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {qr_model_file}")
                    except Exception as e:
                        print(f"âš ï¸  QR CNN ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
                        print("   OpenCV ê¸°ë³¸ QR ê°ì§€ê¸°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                else:
                    print(f"âš ï¸  QR CNN ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {qr_model_file}")
                    print("   OpenCV ê¸°ë³¸ QR ê°ì§€ê¸°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        else:
            print("â„¹ï¸  QR CNN ëª¨ë¸ ë¯¸ì§€ì • - OpenCV ê¸°ë³¸ QR ê°ì§€ê¸° ì‚¬ìš©")
        
        print("\n[ì´ˆê¸°í™” ë‹¨ê³„ 5/5] ì´ˆê¸°í™” ì™„ë£Œ!")
        print("=" * 60)
    
    def _create_env(self):
        """í™˜ê²½ ìƒì„±"""
        if self.env_type == 'carracing':
            try:
                env = CarRacingEnvWrapper(
                    max_steps=self.max_steps,
                    use_extended_actions=self.use_extended_actions,
                    use_discrete_actions=self.use_discrete_actions
                )
                print("âœ… CarRacing í™˜ê²½ ì‚¬ìš©")
                return env
            except ImportError as e:
                print(f"âŒ CarRacing í™˜ê²½ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
                print("ì‹œë®¬ë ˆì´ì…˜ í™˜ê²½ìœ¼ë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
                self.env_type = 'sim'
                return self._create_env()
        
        elif self.env_type == 'sim':
            env = RCCarSimEnv(
                max_steps=self.max_steps,
                use_extended_actions=self.use_extended_actions,
                use_discrete_actions=self.use_discrete_actions
            )
            print("âœ… ì‹œë®¬ë ˆì´ì…˜ í™˜ê²½ ì‚¬ìš©")
            return env
        
        elif self.env_type == 'real':
            if not HAS_REAL_ENV:
                raise ImportError(
                    "ì‹¤ì œ í•˜ë“œì›¨ì–´ í™˜ê²½ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"
                    "ì‹œë®¬ë ˆì´ì…˜ í™˜ê²½ì„ ì‚¬ìš©í•˜ì„¸ìš”: --env-type sim"
                )
            env = RCCarEnv(
                max_steps=self.max_steps,
                use_extended_actions=self.use_extended_actions,
                use_discrete_actions=self.use_discrete_actions
            )
            print("âœ… ì‹¤ì œ í•˜ë“œì›¨ì–´ í™˜ê²½ ì‚¬ìš©")
            return env
        else:
            raise ValueError(f"ì•Œ ìˆ˜ ì—†ëŠ” í™˜ê²½ íƒ€ì…: {self.env_type}")
    
    @staticmethod
    def _normalize_state_array(state: np.ndarray) -> np.ndarray:
        arr = state.astype(np.float32).reshape(-1)
        if arr.max() > 1.0:
            arr = arr / 255.0
        return arr
    
    def _load_agent(self):
        """ì—ì´ì „íŠ¸ ìƒì„± ë° ëª¨ë¸ ë¡œë“œ"""
        probe = self.env.reset()
        probe_state = probe[0] if isinstance(probe, tuple) else probe
        state_vec = self._normalize_state_array(probe_state)
        state_dim = state_vec.shape[0]
        action_dim = 5

        agent = DQNAgent(
            state_dim=state_dim,
            action_dim=action_dim,
            hidden_dim=256,
            latent_dim=256,
            device=self.device,
        )

        # íŒŒì¼ ê²½ë¡œ í™•ì¸ (ìƒëŒ€ ê²½ë¡œ, ì ˆëŒ€ ê²½ë¡œ ëª¨ë‘ í™•ì¸)
        model_file = self.model_path
        if not os.path.isabs(model_file):
            # ìƒëŒ€ ê²½ë¡œì¸ ê²½ìš° ì—¬ëŸ¬ ê°€ëŠ¥í•œ ê²½ë¡œ í™•ì¸
            possible_paths = [
                model_file,  # í˜„ì¬ ë””ë ‰í† ë¦¬ ê¸°ì¤€
                os.path.join('.', model_file),  # í˜„ì¬ ë””ë ‰í† ë¦¬ ëª…ì‹œ
                os.path.join('trained_models', model_file),  # trained_models í´ë”
                os.path.join('trained_models', os.path.basename(model_file)),  # íŒŒì¼ëª…ë§Œ ì‚¬ìš©
            ]
            
            found = False
            for candidate in possible_paths:
                if os.path.exists(candidate):
                    model_file = candidate
                    found = True
                    break
            
            if not found:
                print(f"âš ï¸  ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.model_path}")
                print(f"   ì‹œë„í•œ ê²½ë¡œë“¤:")
                for p in possible_paths:
                    print(f"     - {p} ({'ì¡´ì¬' if os.path.exists(p) else 'ì—†ìŒ'})")
                
                # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ í‘œì‹œ
                trained_models_dir = 'trained_models'
                if os.path.exists(trained_models_dir):
                    available_models = [f for f in os.listdir(trained_models_dir) if f.endswith('.pth')]
                    if available_models:
                        print(f"\n   ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡:")
                        for model in available_models:
                            model_path = os.path.join(trained_models_dir, model)
                            size_mb = os.path.getsize(model_path) / (1024 * 1024)
                            print(f"     - {model} ({size_mb:.1f} MB)")
                
                print("ëœë¤ ì •ì±…ìœ¼ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
                self.env.reset()
                return agent
        
        if os.path.exists(model_file):
            try:
                print(f"ğŸ“¥ ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ ì¤‘: {model_file}")
                agent.load(model_file, strict=False)
                print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_file}")
            except Exception as e:
                print(f"âš ï¸  ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
                print("ëœë¤ ì •ì±…ìœ¼ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
        else:
            print(f"âš ï¸  ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_file}")
            print("ëœë¤ ì •ì±…ìœ¼ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.")

        self.env.reset()
        return agent
    
    def run_episode(self, render: bool = False, verbose: bool = True):
        """
        ë‹¨ì¼ ì—í”¼ì†Œë“œ ì‹¤í–‰
        
        Args:
            render: ë Œë”ë§ ì—¬ë¶€
            verbose: ìƒì„¸ ì¶œë ¥ ì—¬ë¶€
        
        Returns:
            episode_reward: ì—í”¼ì†Œë“œ ì´ ë¦¬ì›Œë“œ
            episode_length: ì—í”¼ì†Œë“œ ê¸¸ì´
        """
        # í™˜ê²½ ë¦¬ì…‹
        reset_result = self.env.reset()
        if isinstance(reset_result, tuple) and len(reset_result) == 2:
            state, _ = reset_result  # Gymnasium
        else:
            state = reset_result  # Gym
        
        # Recurrent ê°€ì • ì œê±°: reset_carry() í˜¸ì¶œ ë¶ˆí•„ìš” (ê° ìŠ¤í…ë§ˆë‹¤ ì´ë¯¸ì§€ ì¸ì½”ë”© ê²°ê³¼ ì‚¬ìš©)
        
        episode_reward = 0.0
        episode_length = 0
        
        if verbose:
            print("\n" + "=" * 60)
            print("AI ì—ì´ì „íŠ¸ ì‹¤í–‰ ì‹œì‘")
            print("=" * 60)
            print(f"ì•¡ì…˜ ê°„ê²©: {self.action_delay:.3f}ì´ˆ")
            print("=" * 60 + "\n")
        
        try:
            for step in range(self.max_steps):
                # QR ì½”ë“œ ì²´í¬ (ì‹¤ì œ í•˜ë“œì›¨ì–´ í™˜ê²½ì¼ ë•Œë§Œ, CNN ëª¨ë¸ ì‚¬ìš©)
                if self.env_type == 'real' and hasattr(self.env, 'rc_car') and self.qr_cnn_detector:
                    try:
                        # CNN ëª¨ë¸ ì‚¬ìš©
                        img = self.env.rc_car.get_raw_image()
                        has_qr, confidence, (qr_absent_prob, qr_present_prob) = self.qr_cnn_detector.detect(
                            img, threshold=0.9, return_probs=True
                        )
                        
                        # QR ê°ì§€ ìƒíƒœ ì¶œë ¥ (ë§¤ ìŠ¤í…ë§ˆë‹¤)
                        if verbose:
                            status = "âœ… QR ìˆìŒ" if has_qr else "âŒ QR ì—†ìŒ"
                            print(f"[QR ì²´í¬] {status} | ì—†ìŒ: {qr_absent_prob:.2%} | ìˆìŒ: {qr_present_prob:.2%} | ì‹ ë¢°ë„: {confidence:.2f}")
                        
                        if has_qr:
                            if verbose:
                                print(f"ğŸ›‘ QR ì½”ë“œ ê°ì§€ (CNN, ì‹ ë¢°ë„: {confidence:.2f}) - 4ì´ˆê°„ ì •ì§€ ì¤‘...")
                            
                            # ì°¨ëŸ‰ ì •ì§€
                            if self.controller:
                                self.controller.execute_discrete_action(0)  # Stop
                            
                            # 4ì´ˆ ëŒ€ê¸°
                            time.sleep(4.0)
                            
                            if verbose:
                                print("ğŸ”„ ì •ì§€ í•´ì œ - ì£¼í–‰ ì¬ê°œ")
                            
                            # ë‹¤ìŒ ìŠ¤í…ìœ¼ë¡œ
                            time.sleep(self.action_delay)
                            continue
                    except Exception as qr_error:
                        if verbose:
                            print(f"âš ï¸  QR ì½”ë“œ ì²´í¬ ì‹¤íŒ¨: {qr_error}")
                
                state_vec = self._normalize_state_array(state)
                action_np = self.agent.act_greedy(state_vec)
                
                # ì‹¤ì œ í•˜ë“œì›¨ì–´ ì œì–´ (real ëª¨ë“œì¼ ë•Œ)
                if self.controller is not None and self.use_discrete_actions:
                    self.controller.execute_discrete_action(action_np)
                
                # í™˜ê²½ ìŠ¤í… ì‹¤í–‰
                next_state, reward, done, info = self.env.step(action_np)
                
                episode_reward += reward
                episode_length += 1
                
                # ì¶œë ¥
                if verbose:
                    action_name = {
                        0: "Stop", 1: "Right+Gas", 2: "Left+Gas", 
                        3: "Gas", 4: "Brake"
                    }.get(action_np, f"Action {action_np}") if self.use_discrete_actions else f"Action {action_np}"
                    
                    print(
                        f"[Step {step+1:4d}] "
                        f"Action: {action_name:12s} | "
                        f"Reward: {reward:7.3f} | "
                        f"Total: {episode_reward:7.3f}"
                    )
                
                # ë Œë”ë§
                if render and hasattr(self.env, 'render'):
                    self.env.render()
                
                # 0.1ì´ˆ ì§€ì—° (ì•¡ì…˜ ê°„ê²©)
                time.sleep(self.action_delay)
                
                # ì—í”¼ì†Œë“œ ì¢…ë£Œ
                if done:
                    break
                
                state = next_state
        
        except KeyboardInterrupt:
            print("\n\nâš ï¸  ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        if verbose:
            print("\n" + "=" * 60)
            print("ì—í”¼ì†Œë“œ ì™„ë£Œ")
            print("=" * 60)
            print(f"ì´ ë¦¬ì›Œë“œ: {episode_reward:.3f}")
            print(f"ì—í”¼ì†Œë“œ ê¸¸ì´: {episode_length} ìŠ¤í…")
            print(f"í‰ê·  ë¦¬ì›Œë“œ: {episode_reward/episode_length:.3f}" if episode_length > 0 else "í‰ê·  ë¦¬ì›Œë“œ: 0.000")
            print("=" * 60 + "\n")
        
        # ì •ì§€ (ì‹¤ì œ í•˜ë“œì›¨ì–´)
        if self.controller is not None:
            self.controller.stop()
        
        return episode_reward, episode_length
    
    def run_multiple_episodes(self, num_episodes: int = 5, render: bool = False, verbose: bool = True):
        """
        ì—¬ëŸ¬ ì—í”¼ì†Œë“œ ì‹¤í–‰
        
        Args:
            num_episodes: ì—í”¼ì†Œë“œ ìˆ˜
            render: ë Œë”ë§ ì—¬ë¶€
            verbose: ìƒì„¸ ì¶œë ¥ ì—¬ë¶€
        
        Returns:
            episode_rewards: ì—í”¼ì†Œë“œ ë¦¬ì›Œë“œ ë¦¬ìŠ¤íŠ¸
            episode_lengths: ì—í”¼ì†Œë“œ ê¸¸ì´ ë¦¬ìŠ¤íŠ¸
        """
        episode_rewards = []
        episode_lengths = []
        
        print(f"\n{'='*60}")
        print(f"ì´ {num_episodes}ê°œ ì—í”¼ì†Œë“œ ì‹¤í–‰")
        print(f"{'='*60}\n")
        
        for episode in range(num_episodes):
            if verbose:
                print(f"\n>>> ì—í”¼ì†Œë“œ {episode + 1}/{num_episodes} <<<")
            
            reward, length = self.run_episode(render=render, verbose=verbose)
            episode_rewards.append(reward)
            episode_lengths.append(length)
            
            # ì—í”¼ì†Œë“œ ê°„ ì§§ì€ ëŒ€ê¸°
            if episode < num_episodes - 1:
                time.sleep(1.0)
        
        # í†µê³„ ì¶œë ¥
        print(f"\n{'='*60}")
        print("ì „ì²´ í†µê³„")
        print(f"{'='*60}")
        print(f"í‰ê·  ë¦¬ì›Œë“œ: {np.mean(episode_rewards):.3f} Â± {np.std(episode_rewards):.3f}")
        print(f"ìµœê³  ë¦¬ì›Œë“œ: {np.max(episode_rewards):.3f}")
        print(f"ìµœì € ë¦¬ì›Œë“œ: {np.min(episode_rewards):.3f}")
        print(f"í‰ê·  ê¸¸ì´: {np.mean(episode_lengths):.1f} Â± {np.std(episode_lengths):.1f} ìŠ¤í…")
        print(f"{'='*60}\n")
        
        return episode_rewards, episode_lengths
    
    def close(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        if self.env:
            self.env.close()
        if self.controller:
            self.controller.close()


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description='AI ì—ì´ì „íŠ¸ ì‹¤í–‰ - í•™ìŠµëœ ëª¨ë¸ë¡œ RC Car ì œì–´',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  # CarRacing í™˜ê²½ì—ì„œ ì‹¤í–‰ (0.1ì´ˆ ê°„ê²©)
  python run_ai_agent.py --model ppo_model.pth --env-type carracing --delay 0.1
  
  # ì‹¤ì œ í•˜ë“œì›¨ì–´ì—ì„œ ì‹¤í–‰ (0.1ì´ˆ ê°„ê²©)
  python run_ai_agent.py --model ppo_model.pth --env-type real --port /dev/ttyACM0 --delay 0.1
  
  # CNN ëª¨ë¸ì„ ì‚¬ìš©í•œ QR ì½”ë“œ ê°ì§€
  python run_ai_agent.py --model ppo_model.pth --env-type real --qr-cnn-model trained_models/qr_cnn_best.pth
  
  # ì—¬ëŸ¬ ì—í”¼ì†Œë“œ ì‹¤í–‰
  python run_ai_agent.py --model ppo_model.pth --episodes 5 --delay 0.1
        """
    )
    
    # ëª¨ë¸ ê²½ë¡œ
    parser.add_argument('--model', type=str, default='trained_models/pretrained_teacher_forcing.pth',
                        help='í•™ìŠµëœ ëª¨ë¸ ê²½ë¡œ (ê¸°ë³¸: trained_models/pretrained_teacher_forcing.pth, ì—†ìœ¼ë©´ ëœë¤ ì •ì±…)')
    
    # í™˜ê²½ ì„¤ì •
    parser.add_argument('--env-type', choices=['carracing', 'sim', 'real'],
                        default='carracing',
                        help='í™˜ê²½ íƒ€ì… (ê¸°ë³¸: carracing)')
    parser.add_argument('--port', type=str, default='/dev/ttyACM0',
                        help='ì‹œë¦¬ì–¼ í¬íŠ¸ (real ëª¨ë“œ ì‚¬ìš© ì‹œ, ê¸°ë³¸: /dev/ttyACM0)')
    parser.add_argument('--max-steps', type=int, default=1000,
                        help='ìµœëŒ€ ìŠ¤í… ìˆ˜ (ê¸°ë³¸: 1000)')
    
    # ì•¡ì…˜ ì„¤ì •
    parser.add_argument('--delay', type=float, default=0.1,
                        help='ì•¡ì…˜ ê°„ ì§€ì—° ì‹œê°„ (ì´ˆ, ê¸°ë³¸: 0.1)')
    parser.add_argument('--use-discrete-actions', action='store_true', default=True,
                        help='ì´ì‚° ì•¡ì…˜ ì‚¬ìš© (ê¸°ë³¸: True)')
    parser.add_argument('--use-continuous-actions', dest='use_discrete_actions', action='store_false',
                        help='ì—°ì† ì•¡ì…˜ ì‚¬ìš©')
    parser.add_argument('--use-extended-actions', action='store_true', default=True,
                        help='í™•ì¥ëœ ì•¡ì…˜ ê³µê°„ ì‚¬ìš© (ê¸°ë³¸: True)')
    
    # ì‹¤í–‰ ì„¤ì •
    parser.add_argument('--episodes', type=int, default=1,
                        help='ì‹¤í–‰í•  ì—í”¼ì†Œë“œ ìˆ˜ (ê¸°ë³¸: 1)')
    parser.add_argument('--render', action='store_true',
                        help='ë Œë”ë§ í™œì„±í™” (ì‹œë®¬ë ˆì´ì…˜/CarRacing ëª¨ë“œ)')
    parser.add_argument('--quiet', action='store_true',
                        help='ìƒì„¸ ì¶œë ¥ ë¹„í™œì„±í™”')
    
    # ë””ë°”ì´ìŠ¤
    parser.add_argument('--device', type=str, default=None,
                        help='ë””ë°”ì´ìŠ¤ (cuda/cpu, ê¸°ë³¸: ìë™ ì„ íƒ)')
    
    # QR CNN ëª¨ë¸
    parser.add_argument('--qr-cnn-model', type=str, default='trained_models/qr_cnn_standard_best.pth',
                        help='QR CNN ëª¨ë¸ ê²½ë¡œ (ê¸°ë³¸: trained_models/qr_cnn_standard_best.pth)')
    parser.add_argument('--no-qr-cnn', action='store_true',
                        help='QR CNN ëª¨ë¸ ì‚¬ìš© ì•ˆ í•¨ (OpenCV ê¸°ë³¸ ê°ì§€ê¸° ì‚¬ìš©)')
    
    args = parser.parse_args()
    
    print("\n" + "=" * 60)
    print("AIAgentRunner ìƒì„± ì‹œì‘")
    print("=" * 60)
    
    # AI ì—ì´ì „íŠ¸ ì‹¤í–‰ê¸° ìƒì„± (ë‹¨ê³„ë³„)
    try:
        print("\n[ë‹¨ê³„ 1] AIAgentRunner ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì¤‘...")
        runner = AIAgentRunner(
            model_path=args.model,
            env_type=args.env_type,
            port=args.port,
            action_delay=args.delay,
            max_steps=args.max_steps,
            use_discrete_actions=args.use_discrete_actions,
            use_extended_actions=args.use_extended_actions,
            device=args.device,
            qr_cnn_model_path=None if args.no_qr_cnn else args.qr_cnn_model
        )
        print("âœ… AIAgentRunner ìƒì„± ì™„ë£Œ")
    except Exception as e:
        print(f"\nâŒ AIAgentRunner ìƒì„± ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
    
    try:
        # ì—í”¼ì†Œë“œ ì‹¤í–‰
        if args.episodes == 1:
            runner.run_episode(render=args.render, verbose=not args.quiet)
        else:
            runner.run_multiple_episodes(
                num_episodes=args.episodes,
                render=args.render,
                verbose=not args.quiet
            )
    finally:
        runner.close()


if __name__ == "__main__":
    main()

