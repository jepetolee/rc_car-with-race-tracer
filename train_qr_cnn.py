#!/usr/bin/env python3
"""
QR ì½”ë“œ ë¶„ë¥˜ CNN ëª¨ë¸ í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸

ìˆ˜ì§‘í•œ ë°ì´í„°ë¡œ CNN ëª¨ë¸ì„ í›ˆë ¨í•©ë‹ˆë‹¤.

ì‚¬ìš©ë²•:
    python train_qr_cnn.py --data-dir qr_dataset --epochs 50
    python train_qr_cnn.py --data-dir qr_dataset --model-type small --epochs 30
"""

import argparse
import os
import sys
import time
import json
from datetime import datetime

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, random_split
from torchvision import transforms
import cv2
import numpy as np
from tqdm import tqdm

from qr_cnn_model import create_model


class QRDataset(Dataset):
    """
    QR ì½”ë“œ ë°ì´í„°ì…‹
    """
    
    def __init__(self, data_dir, transform=None):
        """
        Args:
            data_dir: ë°ì´í„° ë””ë ‰í† ë¦¬ (qr_present, qr_absent í•˜ìœ„ ë””ë ‰í† ë¦¬ í¬í•¨)
            transform: ì´ë¯¸ì§€ ë³€í™˜ (augmentation ë“±)
        """
        self.data_dir = data_dir
        self.transform = transform
        
        # ì´ë¯¸ì§€ íŒŒì¼ê³¼ ë¼ë²¨ ìˆ˜ì§‘
        self.images = []
        self.labels = []
        
        # QR ìˆìŒ ì´ë¯¸ì§€
        qr_dir = os.path.join(data_dir, "qr_present")
        if os.path.exists(qr_dir):
            for filename in os.listdir(qr_dir):
                if filename.lower().endswith(('.png', '.jpg', '.jpeg')):
                    self.images.append(os.path.join(qr_dir, filename))
                    self.labels.append(1)  # QR ìˆìŒ
        
        # QR ì—†ìŒ ì´ë¯¸ì§€
        no_qr_dir = os.path.join(data_dir, "qr_absent")
        if os.path.exists(no_qr_dir):
            for filename in os.listdir(no_qr_dir):
                if filename.lower().endswith(('.png', '.jpg', '.jpeg')):
                    self.images.append(os.path.join(no_qr_dir, filename))
                    self.labels.append(0)  # QR ì—†ìŒ
        
        print(f"ë°ì´í„°ì…‹ ë¡œë“œ ì™„ë£Œ:")
        print(f"  QR ìˆìŒ: {sum(self.labels)}ì¥")
        print(f"  QR ì—†ìŒ: {len(self.labels) - sum(self.labels)}ì¥")
        print(f"  ì´: {len(self.images)}ì¥")
    
    def __len__(self):
        return len(self.images)
    
    def __getitem__(self, idx):
        # ì´ë¯¸ì§€ ë¡œë“œ
        img_path = self.images[idx]
        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
        
        if img is None:
            raise ValueError(f"ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {img_path}")
        
        # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì • (í•„ìš”í•œ ê²½ìš°)
        if img.shape != (320, 320):
            img = cv2.resize(img, (320, 320), interpolation=cv2.INTER_AREA)
        
        # Normalize to [0, 1]
        img = img.astype(np.float32) / 255.0
        
        # (H, W) -> (1, H, W) ì±„ë„ ì¶”ê°€
        img = np.expand_dims(img, axis=0)
        
        # Transform ì ìš©
        if self.transform:
            img = self.transform(torch.from_numpy(img))
        else:
            img = torch.from_numpy(img)
        
        # ë¼ë²¨
        label = torch.tensor(self.labels[idx], dtype=torch.long)
        
        return img, label


def train_epoch(model, dataloader, criterion, optimizer, device):
    """í•œ ì—í­ í›ˆë ¨"""
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0
    
    for images, labels in tqdm(dataloader, desc="í›ˆë ¨ ì¤‘"):
        images = images.to(device)
        labels = labels.to(device)
        
        # Forward pass
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        
        # Backward pass
        loss.backward()
        optimizer.step()
        
        # í†µê³„
        running_loss += loss.item()
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()
    
    epoch_loss = running_loss / len(dataloader)
    epoch_acc = 100.0 * correct / total
    
    return epoch_loss, epoch_acc


def validate(model, dataloader, criterion, device):
    """ê²€ì¦"""
    model.eval()
    running_loss = 0.0
    correct = 0
    total = 0
    
    with torch.no_grad():
        for images, labels in tqdm(dataloader, desc="ê²€ì¦ ì¤‘"):
            images = images.to(device)
            labels = labels.to(device)
            
            outputs = model(images)
            loss = criterion(outputs, labels)
            
            running_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    
    epoch_loss = running_loss / len(dataloader)
    epoch_acc = 100.0 * correct / total
    
    return epoch_loss, epoch_acc


def main():
    parser = argparse.ArgumentParser(
        description='QR ì½”ë“œ ë¶„ë¥˜ CNN ëª¨ë¸ í›ˆë ¨',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  # ê¸°ë³¸ í›ˆë ¨
  python train_qr_cnn.py --data-dir qr_dataset --epochs 50
  
  # ì‘ì€ ëª¨ë¸ë¡œ í›ˆë ¨
  python train_qr_cnn.py --data-dir qr_dataset --model-type small --epochs 30
  
  # í•™ìŠµë¥  ì¡°ì •
  python train_qr_cnn.py --data-dir qr_dataset --lr 0.001 --epochs 50
        """
    )
    
    parser.add_argument('--data-dir', type=str, required=True,
                        help='ë°ì´í„° ë””ë ‰í† ë¦¬ ê²½ë¡œ')
    parser.add_argument('--model-type', type=str, default='standard',
                        choices=['standard', 'small'],
                        help='ëª¨ë¸ íƒ€ì… (ê¸°ë³¸: standard)')
    parser.add_argument('--epochs', type=int, default=50,
                        help='í›ˆë ¨ ì—í­ ìˆ˜ (ê¸°ë³¸: 50)')
    parser.add_argument('--batch-size', type=int, default=16,
                        help='ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸: 16)')
    parser.add_argument('--lr', type=float, default=0.001,
                        help='í•™ìŠµë¥  (ê¸°ë³¸: 0.001)')
    parser.add_argument('--val-split', type=float, default=0.2,
                        help='ê²€ì¦ ë°ì´í„° ë¹„ìœ¨ (ê¸°ë³¸: 0.2)')
    parser.add_argument('--save-dir', type=str, default='trained_models',
                        help='ëª¨ë¸ ì €ì¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸: trained_models)')
    parser.add_argument('--save-name', type=str, default=None,
                        help='ëª¨ë¸ ì €ì¥ ì´ë¦„ (ê¸°ë³¸: qr_cnn_{model_type}_{timestamp}.pth)')
    parser.add_argument('--resume', type=str, default=None,
                        help='ì´ì „ ëª¨ë¸ì—ì„œ ì¬ê°œí•  ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ')
    
    args = parser.parse_args()
    
    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}")
    
    # ë°ì´í„°ì…‹ ë¡œë“œ
    print("\në°ì´í„°ì…‹ ë¡œë“œ ì¤‘...")
    dataset = QRDataset(args.data_dir)
    
    if len(dataset) == 0:
        print("âŒ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € collect_qr_data.pyë¡œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì„¸ìš”.")
        sys.exit(1)
    
    # Train/Val ë¶„í• 
    val_size = int(len(dataset) * args.val_split)
    train_size = len(dataset) - val_size
    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
    
    print(f"\në°ì´í„° ë¶„í• :")
    print(f"  í›ˆë ¨: {train_size}ì¥")
    print(f"  ê²€ì¦: {val_size}ì¥")
    
    # DataLoader ìƒì„±
    train_loader = DataLoader(
        train_dataset,
        batch_size=args.batch_size,
        shuffle=True,
        num_workers=2 if torch.cuda.is_available() else 0
    )
    val_loader = DataLoader(
        val_dataset,
        batch_size=args.batch_size,
        shuffle=False,
        num_workers=2 if torch.cuda.is_available() else 0
    )
    
    # ëª¨ë¸ ìƒì„±
    print(f"\nëª¨ë¸ ìƒì„± ì¤‘... (íƒ€ì…: {args.model_type})")
    model = create_model(model_type=args.model_type, input_size=320, num_classes=2)
    model = model.to(device)
    
    # ì†ì‹¤ í•¨ìˆ˜ ë° ì˜µí‹°ë§ˆì´ì €
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=args.lr)
    
    # ì¬ê°œ
    start_epoch = 0
    best_val_acc = 0.0
    
    if args.resume:
        print(f"ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ: {args.resume}")
        checkpoint = torch.load(args.resume, map_location=device)
        model.load_state_dict(checkpoint['model_state_dict'])
        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        start_epoch = checkpoint['epoch'] + 1
        best_val_acc = checkpoint.get('best_val_acc', 0.0)
        print(f"ì—í­ {start_epoch}ë¶€í„° ì¬ê°œ")
    
    # ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(args.save_dir, exist_ok=True)
    
    # ëª¨ë¸ ì €ì¥ ì´ë¦„
    if args.save_name is None:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        args.save_name = f"qr_cnn_{args.model_type}_{timestamp}.pth"
    
    save_path = os.path.join(args.save_dir, args.save_name)
    best_save_path = os.path.join(args.save_dir, f"qr_cnn_{args.model_type}_best.pth")
    
    print(f"\ní›ˆë ¨ ì‹œì‘...")
    print(f"  ì—í­: {args.epochs}")
    print(f"  ë°°ì¹˜ í¬ê¸°: {args.batch_size}")
    print(f"  í•™ìŠµë¥ : {args.lr}")
    print(f"  ëª¨ë¸ ì €ì¥ ê²½ë¡œ: {save_path}")
    print("=" * 60)
    
    # í›ˆë ¨ ë£¨í”„
    train_history = []
    
    for epoch in range(start_epoch, args.epochs):
        print(f"\nì—í­ {epoch+1}/{args.epochs}")
        
        # í›ˆë ¨
        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)
        
        # ê²€ì¦
        val_loss, val_acc = validate(model, val_loader, criterion, device)
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"  í›ˆë ¨ - Loss: {train_loss:.4f}, Acc: {train_acc:.2f}%")
        print(f"  ê²€ì¦ - Loss: {val_loss:.4f}, Acc: {val_acc:.2f}%")
        
        # íˆìŠ¤í† ë¦¬ ì €ì¥
        train_history.append({
            'epoch': epoch + 1,
            'train_loss': train_loss,
            'train_acc': train_acc,
            'val_loss': val_loss,
            'val_acc': val_acc
        })
        
        # ìµœê³  ëª¨ë¸ ì €ì¥
        if val_acc > best_val_acc:
            best_val_acc = val_acc
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'best_val_acc': best_val_acc,
                'model_type': args.model_type,
                'train_history': train_history
            }, best_save_path)
            print(f"  âœ… ìµœê³  ëª¨ë¸ ì €ì¥: {best_save_path} (ê²€ì¦ ì •í™•ë„: {val_acc:.2f}%)")
        
        # ì£¼ê¸°ì  ì €ì¥
        if (epoch + 1) % 10 == 0:
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'best_val_acc': best_val_acc,
                'model_type': args.model_type,
                'train_history': train_history
            }, save_path)
            print(f"  ğŸ’¾ ì²´í¬í¬ì¸íŠ¸ ì €ì¥: {save_path}")
    
    # ìµœì¢… ëª¨ë¸ ì €ì¥
    torch.save({
        'epoch': args.epochs - 1,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'best_val_acc': best_val_acc,
        'model_type': args.model_type,
        'train_history': train_history
    }, save_path)
    
    print("\n" + "=" * 60)
    print("âœ… í›ˆë ¨ ì™„ë£Œ!")
    print(f"  ìµœê³  ê²€ì¦ ì •í™•ë„: {best_val_acc:.2f}%")
    print(f"  ìµœì¢… ëª¨ë¸: {save_path}")
    print(f"  ìµœê³  ëª¨ë¸: {best_save_path}")


if __name__ == "__main__":
    main()

