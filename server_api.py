#!/usr/bin/env python3
"""
ì„œë²„ API: ë¼ì¦ˆë² ë¦¬ íŒŒì´ì—ì„œ ìˆ˜ì§‘í•œ ë°ì´í„°ë¥¼ ë°›ì•„ í•™ìŠµ ìˆ˜í–‰
Flask ê¸°ë°˜ REST API ì„œë²„
"""

import os
import pickle
import argparse
import uuid
from datetime import datetime
from flask import Flask, request, jsonify, send_file
from flask_cors import CORS
import torch

# í•™ìŠµ ê´€ë ¨ ì„í¬íŠ¸
from train_with_teacher_forcing import TeacherForcingTrainer
from train_ppo import train_ppo
from train_imitation_rl import ImitationRLTrainer
from ppo_agent import PPOAgent

app = Flask(__name__)
CORS(app)  # CORS í—ˆìš© (ë¼ì¦ˆë² ë¦¬ íŒŒì´ì—ì„œ ì ‘ê·¼ ê°€ëŠ¥í•˜ë„ë¡)

# ì „ì—­ ë³€ìˆ˜
UPLOAD_FOLDER = 'uploaded_data'
MODEL_FOLDER = 'trained_models'
TEMP_FOLDER = 'temp_uploads'
os.makedirs(UPLOAD_FOLDER, exist_ok=True)
os.makedirs(MODEL_FOLDER, exist_ok=True)
os.makedirs(TEMP_FOLDER, exist_ok=True)

# ìŠ¤íŠ¸ë¦¬ë° ì—…ë¡œë“œ ì„¸ì…˜ ê´€ë¦¬
upload_sessions = {}  # {session_id: {'filename': str, 'file_size': int, 'chunks': {}, 'total_chunks': int}}


@app.route('/api/health', methods=['GET'])
def health_check():
    """ì„œë²„ ìƒíƒœ í™•ì¸"""
    return jsonify({
        'status': 'ok',
        'timestamp': datetime.now().isoformat()
    })


@app.route('/api/upload_data/init', methods=['POST'])
def upload_data_init():
    """
    ìŠ¤íŠ¸ë¦¬ë° ì—…ë¡œë“œ ì´ˆê¸°í™”
    
    ìš”ì²­:
    - filename: íŒŒì¼ëª…
    - file_size: íŒŒì¼ í¬ê¸°
    - chunk_size: ì²­í¬ í¬ê¸°
    - total_chunks: ì´ ì²­í¬ ìˆ˜
    
    ì‘ë‹µ:
    - session_id: ì„¸ì…˜ ID
    """
    try:
        data = request.json
        filename = data.get('filename')
        file_size = data.get('file_size')
        chunk_size = data.get('chunk_size')
        total_chunks = data.get('total_chunks')
        
        if not all([filename, file_size, chunk_size, total_chunks]):
            return jsonify({'error': 'Missing required fields'}), 400
        
        # ì„¸ì…˜ ID ìƒì„±
        session_id = str(uuid.uuid4())
        
        # ì„¸ì…˜ ì •ë³´ ì €ì¥
        upload_sessions[session_id] = {
            'filename': filename,
            'file_size': file_size,
            'chunk_size': chunk_size,
            'total_chunks': total_chunks,
            'chunks': {},  # {chunk_index: chunk_path}
            'received_chunks': set()
        }
        
        print(f"ğŸ“¥ ì—…ë¡œë“œ ì„¸ì…˜ ì‹œì‘: {session_id} ({filename}, {file_size / (1024*1024):.2f} MB)")
        
        return jsonify({
            'status': 'success',
            'session_id': session_id
        })
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/upload_data/chunk', methods=['POST'])
def upload_data_chunk():
    """
    ì²­í¬ ì—…ë¡œë“œ
    
    ìš”ì²­:
    - session_id: ì„¸ì…˜ ID
    - chunk_index: ì²­í¬ ì¸ë±ìŠ¤
    - chunk: ì²­í¬ ë°ì´í„°
    
    ì‘ë‹µ:
    - status: success
    - received_chunks: ë°›ì€ ì²­í¬ ìˆ˜
    """
    try:
        if 'chunk' not in request.files:
            return jsonify({'error': 'No chunk provided'}), 400
        
        session_id = request.form.get('session_id')
        chunk_index = int(request.form.get('chunk_index'))
        
        if session_id not in upload_sessions:
            return jsonify({'error': 'Invalid session_id'}), 400
        
        session = upload_sessions[session_id]
        chunk = request.files['chunk']
        
        # ì²­í¬ ì €ì¥
        chunk_path = os.path.join(TEMP_FOLDER, f"{session_id}_chunk_{chunk_index}")
        chunk.save(chunk_path)
        
        session['chunks'][chunk_index] = chunk_path
        session['received_chunks'].add(chunk_index)
        
        received = len(session['received_chunks'])
        total = session['total_chunks']
        
        return jsonify({
            'status': 'success',
            'received_chunks': received,
            'total_chunks': total
        })
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/upload_data/finish', methods=['POST'])
def upload_data_finish():
    """
    ì—…ë¡œë“œ ì™„ë£Œ ë° íŒŒì¼ ì¡°ë¦½
    
    ìš”ì²­:
    - session_id: ì„¸ì…˜ ID
    
    ì‘ë‹µ:
    - status: success
    - file_path: ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
    """
    try:
        data = request.json
        session_id = data.get('session_id')
        
        if session_id not in upload_sessions:
            return jsonify({'error': 'Invalid session_id'}), 400
        
        session = upload_sessions[session_id]
        received = len(session['received_chunks'])
        total = session['total_chunks']
        
        if received != total:
            return jsonify({'error': f'Missing chunks: {received}/{total}'}), 400
        
        # íŒŒì¼ ì¡°ë¦½
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"demos_{timestamp}.pkl"
        filepath = os.path.join(UPLOAD_FOLDER, filename)
        
        print(f"ğŸ”¨ íŒŒì¼ ì¡°ë¦½ ì¤‘: {session['filename']} â†’ {filename}")
        
        with open(filepath, 'wb') as f:
            for i in range(total):
                chunk_path = session['chunks'][i]
                with open(chunk_path, 'rb') as chunk_file:
                    f.write(chunk_file.read())
                # ì„ì‹œ ì²­í¬ íŒŒì¼ ì‚­ì œ
                os.remove(chunk_path)
        
        # ì„¸ì…˜ ì‚­ì œ
        del upload_sessions[session_id]
        
        # ë°ì´í„° ê²€ì¦
        try:
            with open(filepath, 'rb') as f:
                data = pickle.load(f)
            num_episodes = len(data.get('demonstrations', []))
            total_steps = sum(len(ep.get('states', [])) for ep in data.get('demonstrations', []))
        except Exception as e:
            return jsonify({'error': f'Invalid pickle file: {str(e)}'}), 400
        
        print(f"âœ… íŒŒì¼ ì¡°ë¦½ ì™„ë£Œ: {filename} ({num_episodes} ì—í”¼ì†Œë“œ, {total_steps} ìŠ¤í…)")
        
        return jsonify({
            'status': 'success',
            'file_path': filepath,
            'filename': filename,
            'num_episodes': num_episodes,
            'total_steps': total_steps
        })
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/upload_data', methods=['POST'])
def upload_data():
    """
    ë¼ì¦ˆë² ë¦¬ íŒŒì´ì—ì„œ ìˆ˜ì§‘í•œ ë°ì´í„° ì—…ë¡œë“œ
    
    ìš”ì²­:
    - Content-Type: multipart/form-data
    - file: pickle íŒŒì¼ (human_demos.pkl)
    
    ì‘ë‹µ:
    - status: success/error
    - file_path: ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
    """
    try:
        if 'file' not in request.files:
            return jsonify({'error': 'No file provided'}), 400
        
        file = request.files['file']
        if file.filename == '':
            return jsonify({'error': 'No file selected'}), 400
        
        # íŒŒì¼ í¬ê¸° í™•ì¸
        file.seek(0, os.SEEK_END)
        file_size = file.tell()
        file_size_mb = file_size / (1024 * 1024)
        file.seek(0)  # ë‹¤ì‹œ ì²˜ìŒìœ¼ë¡œ
        
        print(f"ğŸ“¤ íŒŒì¼ ì—…ë¡œë“œ ì‹œì‘: {file.filename} ({file_size_mb:.2f} MB)")
        
        # íŒŒì¼ ì €ì¥
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"demos_{timestamp}.pkl"
        filepath = os.path.join(UPLOAD_FOLDER, filename)
        
        # ì²­í¬ ë‹¨ìœ„ë¡œ ì €ì¥ (ëŒ€ìš©ëŸ‰ íŒŒì¼ ì§€ì›)
        chunk_size = 1024 * 1024  # 1MB ì²­í¬
        with open(filepath, 'wb') as f:
            while True:
                chunk = file.read(chunk_size)
                if not chunk:
                    break
                f.write(chunk)
        
        # ë°ì´í„° ê²€ì¦
        try:
            with open(filepath, 'rb') as f:
                data = pickle.load(f)
            num_episodes = len(data.get('demonstrations', []))
            total_steps = sum(len(ep.get('states', [])) for ep in data.get('demonstrations', []))
        except Exception as e:
            return jsonify({'error': f'Invalid pickle file: {str(e)}'}), 400
        
        return jsonify({
            'status': 'success',
            'file_path': filepath,
            'filename': filename,
            'num_episodes': num_episodes,
            'total_steps': total_steps
        })
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500


# íŒ¨ì¹˜ ì—…ë¡œë“œë¥¼ ìœ„í•œ ì„ì‹œ ì €ì¥ì†Œ
PATCH_STORAGE = {}  # {session_id: {'patches': [...], 'metadata': {...}}}


@app.route('/api/upload_patch', methods=['POST'])
def upload_patch():
    """
    íŒ¨ì¹˜ ë‹¨ìœ„ë¡œ ë°ì´í„° ì—…ë¡œë“œ (16x16 ì´ë¯¸ì§€ íŒ¨ì¹˜)
    
    ìš”ì²­:
    - session_id: ì„¸ì…˜ ID (ê°™ì€ ì—…ë¡œë“œ ì„¸ì…˜)
    - patch_index: íŒ¨ì¹˜ ì¸ë±ìŠ¤
    - total_patches: ì´ íŒ¨ì¹˜ ìˆ˜
    - states: ì´ë¯¸ì§€ íŒ¨ì¹˜ ë°°ì—´ (16x16 ì´ë¯¸ì§€ë“¤ì˜ ë¦¬ìŠ¤íŠ¸)
    - actions: ì•¡ì…˜ ë°°ì—´
    - metadata: ë©”íƒ€ë°ì´í„° (ì²« íŒ¨ì¹˜ì—ë§Œ)
    
    ì‘ë‹µ:
    - status: success
    - patch_index: ë°›ì€ íŒ¨ì¹˜ ì¸ë±ìŠ¤
    """
    try:
        data = request.json
        session_id = data.get('session_id')
        patch_index = data.get('patch_index')
        total_patches = data.get('total_patches')
        states = data.get('states')
        actions = data.get('actions')
        metadata = data.get('metadata')
        
        if not session_id:
            return jsonify({'error': 'session_id required'}), 400
        
        # ì„¸ì…˜ ì´ˆê¸°í™”
        if session_id not in PATCH_STORAGE:
            PATCH_STORAGE[session_id] = {
                'patches': [],
                'metadata': None,
                'total_patches': total_patches
            }
        
        # íŒ¨ì¹˜ ì €ì¥
        PATCH_STORAGE[session_id]['patches'].append({
            'index': patch_index,
            'states': states,
            'actions': actions
        })
        
        # ë©”íƒ€ë°ì´í„° ì €ì¥ (ì²« íŒ¨ì¹˜)
        if metadata and PATCH_STORAGE[session_id]['metadata'] is None:
            PATCH_STORAGE[session_id]['metadata'] = metadata
        
        return jsonify({
            'status': 'success',
            'patch_index': patch_index,
            'received_patches': len(PATCH_STORAGE[session_id]['patches']),
            'total_patches': total_patches
        })
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/merge_patches', methods=['POST'])
def merge_patches():
    """
    ì—…ë¡œë“œëœ íŒ¨ì¹˜ë“¤ì„ í•˜ë‚˜ì˜ íŒŒì¼ë¡œ ë³‘í•©
    
    ìš”ì²­:
    - session_id: ì„¸ì…˜ ID
    
    ì‘ë‹µ:
    - status: success
    - file_path: ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
    - total_samples: ì´ ìƒ˜í”Œ ìˆ˜
    """
    try:
        data = request.json
        session_id = data.get('session_id')
        
        if not session_id or session_id not in PATCH_STORAGE:
            return jsonify({'error': 'Invalid session_id'}), 400
        
        session_data = PATCH_STORAGE[session_id]
        patches = session_data['patches']
        metadata = session_data['metadata']
        
        if len(patches) == 0:
            return jsonify({'error': 'No patches found'}), 400
        
        # íŒ¨ì¹˜ë“¤ì„ ì¸ë±ìŠ¤ ìˆœìœ¼ë¡œ ì •ë ¬
        patches.sort(key=lambda x: x['index'])
        
        # ëª¨ë“  íŒ¨ì¹˜ ë³‘í•©
        all_states = []
        all_actions = []
        
        for patch in patches:
            all_states.extend(patch['states'])
            all_actions.extend(patch['actions'])
        
        # ì—í”¼ì†Œë“œ í˜•íƒœë¡œ ë³€í™˜ (ë‹¨ì¼ ì—í”¼ì†Œë“œë¡œ)
        demonstrations = [{
            'states': all_states,
            'actions': all_actions,
            'rewards': [0.0] * len(all_states),  # ë¦¬ì›Œë“œëŠ” 0ìœ¼ë¡œ ì„¤ì •
            'dones': [False] * (len(all_states) - 1) + [True],
            'timestamps': []
        }]
        
        # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
        if metadata:
            metadata['num_episodes'] = 1
            metadata['total_steps'] = len(all_states)
        
        # íŒŒì¼ ì €ì¥
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"demos_patched_{timestamp}.pkl"
        filepath = os.path.join(UPLOAD_FOLDER, filename)
        
        with open(filepath, 'wb') as f:
            pickle.dump({
                'metadata': metadata or {},
                'demonstrations': demonstrations
            }, f)
        
        # ì„¸ì…˜ ë°ì´í„° ì‚­ì œ
        del PATCH_STORAGE[session_id]
        
        return jsonify({
            'status': 'success',
            'file_path': filepath,
            'filename': filename,
            'total_samples': len(all_states),
            'num_patches': len(patches)
        })
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/train/supervised', methods=['POST'])
def train_supervised():
    """
    Supervised Learning (Teacher Forcing) í•™ìŠµ ì‹œì‘
    
    ìš”ì²­:
    - file_path: ì—…ë¡œë“œëœ ë°ì´í„° íŒŒì¼ ê²½ë¡œ
    - epochs: í•™ìŠµ ì—í­ ìˆ˜ (ê¸°ë³¸: 100)
    - batch_size: ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸: 64)
    
    ì‘ë‹µ:
    - status: success
    - model_path: í•™ìŠµëœ ëª¨ë¸ ê²½ë¡œ
    """
    try:
        data = request.json
        file_path = data.get('file_path')
        epochs = data.get('epochs', 100)
        batch_size = data.get('batch_size', 64)
        
        if not file_path or not os.path.exists(file_path):
            return jsonify({'error': 'Invalid file_path'}), 400
        
        # ë°ì´í„° ë¡œë“œ
        with open(file_path, 'rb') as f:
            demo_data = pickle.load(f)
        
        demonstrations = demo_data.get('demonstrations', [])
        if len(demonstrations) == 0:
            return jsonify({'error': 'No demonstrations found'}), 400
        
        # ì—ì´ì „íŠ¸ ìƒì„±
        agent = PPOAgent(
            state_dim=256,
            action_dim=5,
            discrete_action=True,
            use_recurrent=False
        )
        
        # Trainer ìƒì„± ë° í•™ìŠµ
        trainer = TeacherForcingTrainer(agent, demonstrations)
        model_path = os.path.join(MODEL_FOLDER, f"pretrained_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pth")
        
        trainer.pretrain(
            epochs=epochs,
            batch_size=batch_size,
            save_path=model_path
        )
        
        return jsonify({
            'status': 'success',
            'model_path': model_path,
            'epochs': epochs
        })
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/train/imitation_rl', methods=['POST'])
def train_imitation_rl_api():
    """
    Imitation Learning via Reinforcement Learning í•™ìŠµ ì‹œì‘
    
    ìš”ì²­:
    - file_path: ì—…ë¡œë“œëœ ë°ëª¨ ë°ì´í„° íŒŒì¼ ê²½ë¡œ
    - model_path: ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ ê²½ë¡œ (ì„ íƒ)
    - epochs: í•™ìŠµ ì—í­ ìˆ˜ (ê¸°ë³¸: 100)
    - batch_size: ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸: 64)
    - learning_rate: í•™ìŠµë¥  (ê¸°ë³¸: 3e-4)
    
    ì‘ë‹µ:
    - status: success
    - model_path: í•™ìŠµëœ ëª¨ë¸ ê²½ë¡œ
    - final_match_rate: ìµœì¢… ì¼ì¹˜ìœ¨
    """
    try:
        data = request.json
        file_path = data.get('file_path')
        model_path = data.get('model_path')
        epochs = data.get('epochs', 100)
        batch_size = data.get('batch_size', 64)
        learning_rate = data.get('learning_rate', 3e-4)
        
        if not file_path or not os.path.exists(file_path):
            return jsonify({'error': 'Invalid file_path'}), 400
        
        # Trainer ìƒì„± ë° í•™ìŠµ
        trainer = ImitationRLTrainer(
            demos_path=file_path,
            model_path=model_path,
            device='cpu',  # ì„œë²„ì—ì„œë„ CPU ì‚¬ìš© (GPUê°€ ìˆë‹¤ë©´ 'cuda'ë¡œ ë³€ê²½)
            learning_rate=learning_rate,
            batch_size=batch_size
        )
        
        model_filename = f"imitation_rl_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pth"
        model_path = os.path.join(MODEL_FOLDER, model_filename)
        
        # í•™ìŠµ ì‹¤í–‰
        trainer.train(
            epochs=epochs,
            save_path=model_path,
            verbose=False  # ì„œë²„ì—ì„œëŠ” ìƒì„¸ ì¶œë ¥ ë¹„í™œì„±í™”
        )
        
        # ìµœì¢… í‰ê°€
        final_match_rate = trainer.evaluate()
        
        return jsonify({
            'status': 'success',
            'model_path': model_path,
            'final_match_rate': float(final_match_rate),
            'epochs': epochs
        })
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/train/ppo', methods=['POST'])
def train_ppo_api():
    """
    PPO ê°•í™”í•™ìŠµ ì‹œì‘
    
    ìš”ì²­:
    - model_path: ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ ê²½ë¡œ (ì„ íƒ)
    - env_type: í™˜ê²½ íƒ€ì… (carracing/sim)
    - total_steps: ì´ í•™ìŠµ ìŠ¤í… ìˆ˜
    - ...
    
    ì‘ë‹µ:
    - status: success
    - model_path: í•™ìŠµëœ ëª¨ë¸ ê²½ë¡œ
    """
    try:
        data = request.json
        # TODO: PPO í•™ìŠµ ë¡œì§ êµ¬í˜„
        return jsonify({
            'status': 'success',
            'message': 'PPO training started (async)'
        })
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/model/latest', methods=['GET'])
def get_latest_model():
    """
    ìµœì‹  ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
    
    ì‘ë‹µ:
    - ëª¨ë¸ íŒŒì¼ (.pth)
    """
    try:
        # MODEL_FOLDERì—ì„œ ìµœì‹  ëª¨ë¸ ì°¾ê¸°
        model_files = [f for f in os.listdir(MODEL_FOLDER) if f.endswith('.pth')]
        if not model_files:
            return jsonify({'error': 'No model found'}), 404
        
        # ìµœì‹  íŒŒì¼ ì„ íƒ (ì´ë¦„ ê¸°ì¤€)
        latest_model = sorted(model_files)[-1]
        model_path = os.path.join(MODEL_FOLDER, latest_model)
        
        return send_file(
            model_path,
            as_attachment=True,
            download_name=latest_model
        )
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/model/list', methods=['GET'])
def list_models():
    """
    ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ
    
    ì‘ë‹µ:
    - models: ëª¨ë¸ íŒŒì¼ ëª©ë¡
    """
    try:
        model_files = [f for f in os.listdir(MODEL_FOLDER) if f.endswith('.pth')]
        model_info = []
        
        for model_file in sorted(model_files, reverse=True):
            model_path = os.path.join(MODEL_FOLDER, model_file)
            stat = os.stat(model_path)
            model_info.append({
                'filename': model_file,
                'size': stat.st_size,
                'modified': datetime.fromtimestamp(stat.st_mtime).isoformat()
            })
        
        return jsonify({
            'models': model_info
        })
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/inference', methods=['POST'])
def inference():
    """
    ì‹¤ì‹œê°„ ì¶”ë¡  (ì„ íƒ ì‚¬í•­)
    
    ìš”ì²­:
    - state: 256ì°¨ì› ìƒíƒœ ë²¡í„° (16x16 ì´ë¯¸ì§€)
    - model_path: ì‚¬ìš©í•  ëª¨ë¸ ê²½ë¡œ (ì„ íƒ, ê¸°ë³¸: ìµœì‹  ëª¨ë¸)
    
    ì‘ë‹µ:
    - action: ì¶”ë¡ ëœ ì•¡ì…˜ (0-4)
    - log_prob: ë¡œê·¸ í™•ë¥ 
    - value: ìƒíƒœ ê°€ì¹˜
    """
    try:
        data = request.json
        state = data.get('state')
        model_path = data.get('model_path')
        
        if state is None:
            return jsonify({'error': 'No state provided'}), 400
        
        # ëª¨ë¸ ë¡œë“œ
        if model_path is None:
            # ìµœì‹  ëª¨ë¸ ì‚¬ìš©
            model_files = [f for f in os.listdir(MODEL_FOLDER) if f.endswith('.pth')]
            if not model_files:
                return jsonify({'error': 'No model found'}), 404
            model_path = os.path.join(MODEL_FOLDER, sorted(model_files)[-1])
        
        # ì—ì´ì „íŠ¸ ë¡œë“œ ë° ì¶”ë¡ 
        agent = PPOAgent(
            state_dim=256,
            action_dim=5,
            discrete_action=True
        )
        agent.load(model_path)
        
        # ì¶”ë¡  (recurrent ê°’ ìŠ¹ê³„ë¥¼ ìœ„í•´ get_action_with_carry ì‚¬ìš©)
        state_tensor = torch.FloatTensor(state).unsqueeze(0)
        if hasattr(agent, 'use_recurrent') and agent.use_recurrent:
            action, log_prob, value, _ = agent.get_action_with_carry(
                state_tensor, deterministic=True
            )
        else:
            action, log_prob, value = agent.actor_critic.get_action(state_tensor)
        
        return jsonify({
            'action': int(action.item()),
            'log_prob': float(log_prob.item()),
            'value': float(value.item())
        })
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500


def main():
    parser = argparse.ArgumentParser(description='RC Car í•™ìŠµ ì„œë²„ API')
    parser.add_argument('--host', type=str, default='0.0.0.0',
                        help='ì„œë²„ í˜¸ìŠ¤íŠ¸ (ê¸°ë³¸: 0.0.0.0)')
    parser.add_argument('--port', type=int, default=5000,
                        help='ì„œë²„ í¬íŠ¸ (ê¸°ë³¸: 5000)')
    parser.add_argument('--debug', action='store_true',
                        help='ë””ë²„ê·¸ ëª¨ë“œ')
    
    args = parser.parse_args()
    
    print(f"ğŸš€ ì„œë²„ ì‹œì‘: http://{args.host}:{args.port}")
    print(f"ğŸ“ ì—…ë¡œë“œ í´ë”: {UPLOAD_FOLDER}")
    print(f"ğŸ“ ëª¨ë¸ í´ë”: {MODEL_FOLDER}")
    
    app.run(host=args.host, port=args.port, debug=args.debug)


if __name__ == '__main__':
    main()

