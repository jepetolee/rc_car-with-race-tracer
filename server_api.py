#!/usr/bin/env python3
"""
ì„œë²„ API: ë¼ì¦ˆë² ë¦¬ íŒŒì´ì—ì„œ ìˆ˜ì§‘í•œ ë°ì´í„°ë¥¼ ë°›ì•„ í•™ìŠµ ìˆ˜í–‰
Flask ê¸°ë°˜ REST API ì„œë²„
"""

import os
import pickle
import argparse
import uuid
import numpy as np
from datetime import datetime
from flask import Flask, request, jsonify, send_file
from flask_cors import CORS
import torch

# í•™ìŠµ ê´€ë ¨ ì„í¬íŠ¸
from train_with_teacher_forcing import TeacherForcingTrainer
from train_ppo import train_ppo
from train_imitation_rl import ImitationRLTrainer
from ppo_agent import PPOAgent

app = Flask(__name__)
CORS(app)  # CORS í—ˆìš© (ë¼ì¦ˆë² ë¦¬ íŒŒì´ì—ì„œ ì ‘ê·¼ ê°€ëŠ¥í•˜ë„ë¡)

# ì „ì—­ ë³€ìˆ˜
UPLOAD_FOLDER = 'uploaded_data'
MODEL_FOLDER = 'trained_models'
TEMP_FOLDER = 'temp_uploads'
os.makedirs(UPLOAD_FOLDER, exist_ok=True)
os.makedirs(MODEL_FOLDER, exist_ok=True)
os.makedirs(TEMP_FOLDER, exist_ok=True)

# ìŠ¤íŠ¸ë¦¬ë° ì—…ë¡œë“œ ì„¸ì…˜ ê´€ë¦¬
upload_sessions = {}  # {session_id: {'filename': str, 'file_size': int, 'chunks': {}, 'total_chunks': int}}


@app.route('/api/health', methods=['GET'])
def health_check():
    """ì„œë²„ ìƒíƒœ í™•ì¸"""
    return jsonify({
        'status': 'ok',
        'timestamp': datetime.now().isoformat()
    })


@app.route('/api/upload_data/init', methods=['POST'])
def upload_data_init():
    """
    ìŠ¤íŠ¸ë¦¬ë° ì—…ë¡œë“œ ì´ˆê¸°í™”
    
    ìš”ì²­:
    - filename: íŒŒì¼ëª…
    - file_size: íŒŒì¼ í¬ê¸°
    - chunk_size: ì²­í¬ í¬ê¸°
    - total_chunks: ì´ ì²­í¬ ìˆ˜
    
    ì‘ë‹µ:
    - session_id: ì„¸ì…˜ ID
    """
    try:
        if not request.is_json:
            return jsonify({'error': 'Content-Type must be application/json'}), 400
        
        data = request.json
        if not data:
            return jsonify({'error': 'No JSON data provided'}), 400
        
        filename = data.get('filename')
        file_size = data.get('file_size')
        chunk_size = data.get('chunk_size')
        total_chunks = data.get('total_chunks')
        
        if not all([filename, file_size is not None, chunk_size is not None, total_chunks is not None]):
            return jsonify({
                'error': 'Missing required fields',
                'received': {
                    'filename': filename,
                    'file_size': file_size,
                    'chunk_size': chunk_size,
                    'total_chunks': total_chunks
                }
            }), 400
        
        # ì„¸ì…˜ ID ìƒì„±
        session_id = str(uuid.uuid4())
        
        # ì„¸ì…˜ ì •ë³´ ì €ì¥
        upload_sessions[session_id] = {
            'filename': filename,
            'file_size': file_size,
            'chunk_size': chunk_size,
            'total_chunks': total_chunks,
            'chunks': {},  # {chunk_index: chunk_path}
            'received_chunks': set()
        }
        
        print(f"ğŸ“¥ ì—…ë¡œë“œ ì„¸ì…˜ ì‹œì‘: {session_id} ({filename}, {file_size / (1024*1024):.2f} MB)")
        
        return jsonify({
            'status': 'success',
            'session_id': session_id
        })
    
    except Exception as e:
        import traceback
        error_msg = str(e)
        traceback.print_exc()
        return jsonify({'error': f'Server error: {error_msg}'}), 500


@app.route('/api/upload_data/chunk', methods=['POST'])
def upload_data_chunk():
    """
    ì²­í¬ ì—…ë¡œë“œ
    
    ìš”ì²­:
    - session_id: ì„¸ì…˜ ID
    - chunk_index: ì²­í¬ ì¸ë±ìŠ¤
    - chunk: ì²­í¬ ë°ì´í„°
    
    ì‘ë‹µ:
    - status: success
    - received_chunks: ë°›ì€ ì²­í¬ ìˆ˜
    """
    try:
        if 'chunk' not in request.files:
            return jsonify({'error': 'No chunk provided'}), 400
        
        session_id = request.form.get('session_id')
        chunk_index = int(request.form.get('chunk_index'))
        
        if session_id not in upload_sessions:
            return jsonify({'error': 'Invalid session_id'}), 400
        
        session = upload_sessions[session_id]
        chunk = request.files['chunk']
        
        # ì²­í¬ ì €ì¥
        chunk_path = os.path.join(TEMP_FOLDER, f"{session_id}_chunk_{chunk_index}")
        chunk.save(chunk_path)
        
        session['chunks'][chunk_index] = chunk_path
        session['received_chunks'].add(chunk_index)
        
        received = len(session['received_chunks'])
        total = session['total_chunks']
        
        return jsonify({
            'status': 'success',
            'received_chunks': received,
            'total_chunks': total
        })
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/upload_data/finish', methods=['POST'])
def upload_data_finish():
    """
    ì—…ë¡œë“œ ì™„ë£Œ ë° íŒŒì¼ ì¡°ë¦½
    
    ìš”ì²­:
    - session_id: ì„¸ì…˜ ID
    
    ì‘ë‹µ:
    - status: success
    - file_path: ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
    """
    try:
        data = request.json
        session_id = data.get('session_id')
        
        if session_id not in upload_sessions:
            return jsonify({'error': 'Invalid session_id'}), 400
        
        session = upload_sessions[session_id]
        received = len(session['received_chunks'])
        total = session['total_chunks']
        
        if received != total:
            return jsonify({'error': f'Missing chunks: {received}/{total}'}), 400
        
        # íŒŒì¼ ì¡°ë¦½
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"demos_{timestamp}.pkl"
        filepath = os.path.join(UPLOAD_FOLDER, filename)
        
        print(f"ğŸ”¨ íŒŒì¼ ì¡°ë¦½ ì¤‘: {session['filename']} â†’ {filename}")
        
        with open(filepath, 'wb') as f:
            for i in range(total):
                chunk_path = session['chunks'][i]
                with open(chunk_path, 'rb') as chunk_file:
                    f.write(chunk_file.read())
                # ì„ì‹œ ì²­í¬ íŒŒì¼ ì‚­ì œ
                os.remove(chunk_path)
        
        # ì„¸ì…˜ ì‚­ì œ
        del upload_sessions[session_id]
        
        # ë°ì´í„° ê²€ì¦
        try:
            with open(filepath, 'rb') as f:
                data = pickle.load(f)
            num_episodes = len(data.get('demonstrations', []))
            total_steps = sum(len(ep.get('states', [])) for ep in data.get('demonstrations', []))
        except Exception as e:
            return jsonify({'error': f'Invalid pickle file: {str(e)}'}), 400
        
        print(f"âœ… íŒŒì¼ ì¡°ë¦½ ì™„ë£Œ: {filename} ({num_episodes} ì—í”¼ì†Œë“œ, {total_steps} ìŠ¤í…)")
        
        return jsonify({
            'status': 'success',
            'file_path': filepath,
            'filename': filename,
            'num_episodes': num_episodes,
            'total_steps': total_steps
        })
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/upload_data', methods=['POST'])
def upload_data():
    """
    ë¼ì¦ˆë² ë¦¬ íŒŒì´ì—ì„œ ìˆ˜ì§‘í•œ ë°ì´í„° ì—…ë¡œë“œ
    
    ìš”ì²­:
    - Content-Type: multipart/form-data
    - file: pickle íŒŒì¼ (human_demos.pkl)
    
    ì‘ë‹µ:
    - status: success/error
    - file_path: ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
    """
    try:
        if 'file' not in request.files:
            return jsonify({'error': 'No file provided'}), 400
        
        file = request.files['file']
        if file.filename == '':
            return jsonify({'error': 'No file selected'}), 400
        
        # íŒŒì¼ í¬ê¸° í™•ì¸
        file.seek(0, os.SEEK_END)
        file_size = file.tell()
        file_size_mb = file_size / (1024 * 1024)
        file.seek(0)  # ë‹¤ì‹œ ì²˜ìŒìœ¼ë¡œ
        
        print(f"ğŸ“¤ íŒŒì¼ ì—…ë¡œë“œ ì‹œì‘: {file.filename} ({file_size_mb:.2f} MB)")
        
        # íŒŒì¼ ì €ì¥
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"demos_{timestamp}.pkl"
        filepath = os.path.join(UPLOAD_FOLDER, filename)
        
        # ì²­í¬ ë‹¨ìœ„ë¡œ ì €ì¥ (ëŒ€ìš©ëŸ‰ íŒŒì¼ ì§€ì›)
        chunk_size = 1024 * 1024  # 1MB ì²­í¬
        with open(filepath, 'wb') as f:
            while True:
                chunk = file.read(chunk_size)
                if not chunk:
                    break
                f.write(chunk)
        
        # ë°ì´í„° ê²€ì¦
        try:
            with open(filepath, 'rb') as f:
                data = pickle.load(f)
            num_episodes = len(data.get('demonstrations', []))
            total_steps = sum(len(ep.get('states', [])) for ep in data.get('demonstrations', []))
        except Exception as e:
            return jsonify({'error': f'Invalid pickle file: {str(e)}'}), 400
        
        return jsonify({
            'status': 'success',
            'file_path': filepath,
            'filename': filename,
            'num_episodes': num_episodes,
            'total_steps': total_steps
        })
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500


# íŒ¨ì¹˜ ì—…ë¡œë“œë¥¼ ìœ„í•œ ì„ì‹œ ì €ì¥ì†Œ
PATCH_STORAGE = {}  # {session_id: {'patches': [...], 'metadata': {...}}}


@app.route('/api/upload_patch', methods=['POST'])
def upload_patch():
    """
    íŒ¨ì¹˜ ë‹¨ìœ„ë¡œ ë°ì´í„° ì—…ë¡œë“œ (16x16 ì´ë¯¸ì§€ íŒ¨ì¹˜)
    
    ìš”ì²­:
    - session_id: ì„¸ì…˜ ID (ê°™ì€ ì—…ë¡œë“œ ì„¸ì…˜)
    - patch_index: íŒ¨ì¹˜ ì¸ë±ìŠ¤
    - total_patches: ì´ íŒ¨ì¹˜ ìˆ˜
    - states: ì´ë¯¸ì§€ íŒ¨ì¹˜ ë°°ì—´ (16x16 ì´ë¯¸ì§€ë“¤ì˜ ë¦¬ìŠ¤íŠ¸)
    - actions: ì•¡ì…˜ ë°°ì—´
    - metadata: ë©”íƒ€ë°ì´í„° (ì²« íŒ¨ì¹˜ì—ë§Œ)
    
    ì‘ë‹µ:
    - status: success
    - patch_index: ë°›ì€ íŒ¨ì¹˜ ì¸ë±ìŠ¤
    """
    try:
        data = request.json
        session_id = data.get('session_id')
        patch_index = data.get('patch_index')
        total_patches = data.get('total_patches')
        states = data.get('states')
        actions = data.get('actions')
        metadata = data.get('metadata')
        
        if not session_id:
            return jsonify({'error': 'session_id required'}), 400
        
        # ì„¸ì…˜ ì´ˆê¸°í™”
        if session_id not in PATCH_STORAGE:
            PATCH_STORAGE[session_id] = {
                'patches': [],
                'metadata': None,
                'total_patches': total_patches
            }
        
        # íŒ¨ì¹˜ ì €ì¥
        PATCH_STORAGE[session_id]['patches'].append({
            'index': patch_index,
            'states': states,
            'actions': actions
        })
        
        # ë©”íƒ€ë°ì´í„° ì €ì¥ (ì²« íŒ¨ì¹˜)
        if metadata and PATCH_STORAGE[session_id]['metadata'] is None:
            PATCH_STORAGE[session_id]['metadata'] = metadata
        
        return jsonify({
            'status': 'success',
            'patch_index': patch_index,
            'received_patches': len(PATCH_STORAGE[session_id]['patches']),
            'total_patches': total_patches
        })
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/merge_patches', methods=['POST'])
def merge_patches():
    """
    ì—…ë¡œë“œëœ íŒ¨ì¹˜ë“¤ì„ í•˜ë‚˜ì˜ íŒŒì¼ë¡œ ë³‘í•©
    
    ìš”ì²­:
    - session_id: ì„¸ì…˜ ID
    
    ì‘ë‹µ:
    - status: success
    - file_path: ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
    - total_samples: ì´ ìƒ˜í”Œ ìˆ˜
    """
    try:
        data = request.json
        session_id = data.get('session_id')
        
        if not session_id or session_id not in PATCH_STORAGE:
            return jsonify({'error': 'Invalid session_id'}), 400
        
        session_data = PATCH_STORAGE[session_id]
        patches = session_data['patches']
        metadata = session_data['metadata']
        
        if len(patches) == 0:
            return jsonify({'error': 'No patches found'}), 400
        
        # íŒ¨ì¹˜ë“¤ì„ ì¸ë±ìŠ¤ ìˆœìœ¼ë¡œ ì •ë ¬
        patches.sort(key=lambda x: x['index'])
        
        # ëª¨ë“  íŒ¨ì¹˜ ë³‘í•©
        all_states = []
        all_actions = []
        
        for patch in patches:
            all_states.extend(patch['states'])
            all_actions.extend(patch['actions'])
        
        # ì—í”¼ì†Œë“œ í˜•íƒœë¡œ ë³€í™˜ (ë‹¨ì¼ ì—í”¼ì†Œë“œë¡œ)
        demonstrations = [{
            'states': all_states,
            'actions': all_actions,
            'rewards': [0.0] * len(all_states),  # ë¦¬ì›Œë“œëŠ” 0ìœ¼ë¡œ ì„¤ì •
            'dones': [False] * (len(all_states) - 1) + [True],
            'timestamps': []
        }]
        
        # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
        if metadata:
            metadata['num_episodes'] = 1
            metadata['total_steps'] = len(all_states)
        
        # íŒŒì¼ ì €ì¥
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"demos_patched_{timestamp}.pkl"
        filepath = os.path.join(UPLOAD_FOLDER, filename)
        
        with open(filepath, 'wb') as f:
            pickle.dump({
                'metadata': metadata or {},
                'demonstrations': demonstrations
            }, f)
        
        # ì„¸ì…˜ ë°ì´í„° ì‚­ì œ
        del PATCH_STORAGE[session_id]
        
        return jsonify({
            'status': 'success',
            'file_path': filepath,
            'filename': filename,
            'total_samples': len(all_states),
            'num_patches': len(patches)
        })
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/train/supervised', methods=['POST'])
def train_supervised():
    """
    Supervised Learning (Teacher Forcing) í•™ìŠµ ì‹œì‘
    
    ìš”ì²­:
    - file_path: ì—…ë¡œë“œëœ ë°ì´í„° íŒŒì¼ ê²½ë¡œ
    - model_path: ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ ê²½ë¡œ (ì„ íƒ, ì—†ìœ¼ë©´ ëœë¤ ì´ˆê¸°í™”)
    - epochs: í•™ìŠµ ì—í­ ìˆ˜ (ê¸°ë³¸: 100)
    - batch_size: ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸: 64)
    - learning_rate: í•™ìŠµë¥  (ê¸°ë³¸: 3e-4)
    
    ì‘ë‹µ:
    - status: success
    - model_path: í•™ìŠµëœ ëª¨ë¸ ê²½ë¡œ
    """
    try:
        data = request.json
        file_path = data.get('file_path')
        model_path = data.get('model_path')
        epochs = data.get('epochs', 100)
        batch_size = data.get('batch_size', 64)
        learning_rate = data.get('learning_rate', 3e-4)
        
        print(f"ğŸ“š Teacher Forcing í•™ìŠµ ìš”ì²­:")
        print(f"   ë°›ì€ ë°ì´í„°: {data}")
        print(f"   íŒŒì¼: {file_path}")
        print(f"   ì—í­: {epochs}")
        print(f"   ë°°ì¹˜ í¬ê¸°: {batch_size}")
        print(f"   í•™ìŠµë¥ : {learning_rate}")
        
        if not file_path:
            return jsonify({'error': 'file_path is required'}), 400
        
        # íŒŒì¼ ê²½ë¡œ í™•ì¸ (ì ˆëŒ€ ê²½ë¡œ ë˜ëŠ” ìƒëŒ€ ê²½ë¡œ)
        if not os.path.isabs(file_path):
            # ìƒëŒ€ ê²½ë¡œì¸ ê²½ìš° UPLOAD_FOLDER ê¸°ì¤€ìœ¼ë¡œ ë³€í™˜
            file_path = os.path.join(UPLOAD_FOLDER, os.path.basename(file_path))
        
        print(f"   ì‹¤ì œ íŒŒì¼ ê²½ë¡œ: {file_path}")
        print(f"   íŒŒì¼ ì¡´ì¬ ì—¬ë¶€: {os.path.exists(file_path)}")
        
        if not os.path.exists(file_path):
            available_files = []
            if os.path.exists(UPLOAD_FOLDER):
                available_files = [f for f in os.listdir(UPLOAD_FOLDER) if f.endswith('.pkl')]
            return jsonify({
                'error': f'File not found: {file_path}',
                'upload_folder': UPLOAD_FOLDER,
                'available_files': available_files[:10]
            }), 400
        
        # ë°ì´í„° ë¡œë“œ
        with open(file_path, 'rb') as f:
            demo_data = pickle.load(f)
        
        demonstrations = demo_data.get('demonstrations', [])
        if len(demonstrations) == 0:
            return jsonify({'error': 'No demonstrations found'}), 400
        
        # ìƒíƒœ ì°¨ì› ìë™ ê°ì§€
        state_dim = None
        if len(demonstrations) > 0:
            first_episode = demonstrations[0]
            states = first_episode.get('states', [])
            if len(states) > 0:
                first_state = np.array(states[0])
                if len(first_state.shape) == 1:
                    state_dim = first_state.shape[0]
                else:
                    state_dim = first_state.size
                print(f"ğŸ“ ìƒíƒœ ì°¨ì› ìë™ ê°ì§€: {state_dim}")
        
        if state_dim is None:
            return jsonify({'error': 'Could not determine state_dim from demonstrations'}), 400
        
        # ì•¡ì…˜ ì°¨ì› í™•ì¸
        first_episode = demonstrations[0]
        actions = first_episode.get('actions', [])
        if len(actions) > 0:
            action_dim = 5  # ê¸°ë³¸ê°’ (discrete actions: 0-4)
            print(f"ğŸ“ ì•¡ì…˜ ì°¨ì›: {action_dim} (discrete)")
        else:
            return jsonify({'error': 'Could not determine action_dim from demonstrations'}), 400
        
        # ì—ì´ì „íŠ¸ ìƒì„±
        agent = PPOAgent(
            state_dim=state_dim,
            action_dim=action_dim,
            discrete_action=True,
            use_recurrent=False
        )
        
        # ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ (ì„ íƒ)
        if model_path:
            if not os.path.isabs(model_path):
                # ìƒëŒ€ ê²½ë¡œì¸ ê²½ìš° í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë˜ëŠ” MODEL_FOLDER í™•ì¸
                if os.path.exists(model_path):
                    pass
                elif os.path.exists(os.path.join(MODEL_FOLDER, model_path)):
                    model_path = os.path.join(MODEL_FOLDER, model_path)
            
            if os.path.exists(model_path):
                print(f"ğŸ“¥ ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ: {model_path}")
                agent.load(model_path)
                print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            else:
                print(f"âš ï¸  ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
                print(f"   ëœë¤ ì´ˆê¸°í™”ë¡œ ì‹œì‘í•©ë‹ˆë‹¤.")
        else:
            # ê¸°ë³¸ ëª¨ë¸ í™•ì¸
            default_model = 'a3c_model_best.pth'
            if os.path.exists(default_model):
                print(f"ğŸ“¥ ê¸°ë³¸ ëª¨ë¸ ë¡œë“œ: {default_model}")
                agent.load(default_model)
                print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            elif os.path.exists(os.path.join(MODEL_FOLDER, default_model)):
                model_path = os.path.join(MODEL_FOLDER, default_model)
                print(f"ğŸ“¥ ê¸°ë³¸ ëª¨ë¸ ë¡œë“œ: {model_path}")
                agent.load(model_path)
                print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            else:
                print(f"âš ï¸  ê¸°ë³¸ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ëœë¤ ì´ˆê¸°í™”ë¡œ ì‹œì‘í•©ë‹ˆë‹¤.")
        
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
        print(f"ë””ë°”ì´ìŠ¤: {device}")
        
        # Trainer ìƒì„± ë° í•™ìŠµ
        trainer = TeacherForcingTrainer(agent, demonstrations, device=device, lr=learning_rate)
        model_path = os.path.join(MODEL_FOLDER, f"pretrained_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pth")
        
        trainer.pretrain(
            epochs=epochs,
            batch_size=batch_size,
            save_path=model_path,
            verbose=True
        )
        
        return jsonify({
            'status': 'success',
            'model_path': model_path,
            'epochs': epochs,
            'state_dim': state_dim
        })
    
    except Exception as e:
        import traceback
        error_msg = str(e)
        error_trace = traceback.format_exc()
        print(f"âŒ Teacher Forcing í•™ìŠµ ì‹¤íŒ¨:")
        print(error_trace)
        return jsonify({
            'error': error_msg,
            'traceback': error_trace
        }), 500


@app.route('/api/train/imitation_rl', methods=['POST'])
def train_imitation_rl_api():
    """
    Imitation Learning via Reinforcement Learning í•™ìŠµ ì‹œì‘
    
    ìš”ì²­:
    - file_path: ì—…ë¡œë“œëœ ë°ëª¨ ë°ì´í„° íŒŒì¼ ê²½ë¡œ
    - model_path: ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ ê²½ë¡œ (ì„ íƒ)
    - epochs: í•™ìŠµ ì—í­ ìˆ˜ (ê¸°ë³¸: 100)
    - batch_size: ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸: 64)
    - learning_rate: í•™ìŠµë¥  (ê¸°ë³¸: 3e-4)
    
    ì‘ë‹µ:
    - status: success
    - model_path: í•™ìŠµëœ ëª¨ë¸ ê²½ë¡œ
    - final_match_rate: ìµœì¢… ì¼ì¹˜ìœ¨
    """
    try:
        if not request.is_json:
            return jsonify({'error': 'Content-Type must be application/json'}), 400
        
        data = request.json
        if not data:
            return jsonify({'error': 'No JSON data provided'}), 400
        
        file_path = data.get('file_path')
        model_path = data.get('model_path')
        epochs = data.get('epochs', 100)
        batch_size = data.get('batch_size', 64)
        learning_rate = data.get('learning_rate', 3e-4)
        
        print(f"ğŸ“š Imitation RL í•™ìŠµ ìš”ì²­:")
        print(f"   ë°›ì€ ë°ì´í„°: {data}")
        print(f"   íŒŒì¼: {file_path}")
        print(f"   ì—í­: {epochs}")
        print(f"   ë°°ì¹˜ í¬ê¸°: {batch_size}")
        print(f"   í•™ìŠµë¥ : {learning_rate}")
        
        if not file_path:
            return jsonify({
                'error': 'file_path is required',
                'received_data': data
            }), 400
        
        # íŒŒì¼ ê²½ë¡œ í™•ì¸ (ì ˆëŒ€ ê²½ë¡œ ë˜ëŠ” ìƒëŒ€ ê²½ë¡œ)
        if not os.path.isabs(file_path):
            # ìƒëŒ€ ê²½ë¡œì¸ ê²½ìš° UPLOAD_FOLDER ê¸°ì¤€ìœ¼ë¡œ ë³€í™˜
            file_path = os.path.join(UPLOAD_FOLDER, os.path.basename(file_path))
        
        print(f"   ì‹¤ì œ íŒŒì¼ ê²½ë¡œ: {file_path}")
        print(f"   íŒŒì¼ ì¡´ì¬ ì—¬ë¶€: {os.path.exists(file_path)}")
        
        if not os.path.exists(file_path):
            # íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ì„ ë•Œ ê°€ëŠ¥í•œ íŒŒì¼ ëª©ë¡ í‘œì‹œ
            available_files = []
            if os.path.exists(UPLOAD_FOLDER):
                available_files = [f for f in os.listdir(UPLOAD_FOLDER) if f.endswith('.pkl')]
            return jsonify({
                'error': f'File not found: {file_path}',
                'upload_folder': UPLOAD_FOLDER,
                'available_files': available_files[:10]  # ìµœëŒ€ 10ê°œë§Œ í‘œì‹œ
            }), 400
        
        # model_pathê°€ ì œê³µë˜ì§€ ì•Šìœ¼ë©´ ê¸°ë³¸ê°’ìœ¼ë¡œ a3c_model_best.pth ì‚¬ìš©
        if not model_path:
            default_model = 'a3c_model_best.pth'
            # í”„ë¡œì íŠ¸ ë£¨íŠ¸ì™€ MODEL_FOLDER ë‘˜ ë‹¤ í™•ì¸
            if os.path.exists(default_model):
                model_path = default_model
            elif os.path.exists(os.path.join(MODEL_FOLDER, default_model)):
                model_path = os.path.join(MODEL_FOLDER, default_model)
            else:
                print(f"âš ï¸  ê¸°ë³¸ ëª¨ë¸({default_model})ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ëœë¤ ì´ˆê¸°í™”ë¡œ ì‹œì‘í•©ë‹ˆë‹¤.")
                model_path = None
        
        if model_path:
            print(f"   ì‚¬ì „ í•™ìŠµ ëª¨ë¸: {model_path}")
            if not os.path.exists(model_path):
                print(f"âš ï¸  ëª¨ë¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {model_path}")
                print(f"   ëœë¤ ì´ˆê¸°í™”ë¡œ ì‹œì‘í•©ë‹ˆë‹¤.")
                model_path = None
        
        # ë””ë°”ì´ìŠ¤ ì„ íƒ (GPU ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ cuda, ì•„ë‹ˆë©´ cpu)
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
        print(f"   ë””ë°”ì´ìŠ¤: {device}")
        
        # Trainer ìƒì„± ë° í•™ìŠµ
        try:
            trainer = ImitationRLTrainer(
                demos_path=file_path,
                model_path=model_path,
                device=device,
                learning_rate=learning_rate,
                batch_size=batch_size
            )
        except Exception as e:
            import traceback
            error_msg = f"Trainer ìƒì„± ì‹¤íŒ¨: {str(e)}"
            print(f"âŒ {error_msg}")
            traceback.print_exc()
            return jsonify({'error': error_msg}), 500
        
        model_filename = f"imitation_rl_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pth"
        model_path = os.path.join(MODEL_FOLDER, model_filename)
        
        # í•™ìŠµ ì‹¤í–‰
        try:
            print(f"ğŸš€ í•™ìŠµ ì‹œì‘...")
            trainer.train(
                epochs=epochs,
                save_path=model_path,
                verbose=False  # ì„œë²„ì—ì„œëŠ” ìƒì„¸ ì¶œë ¥ ë¹„í™œì„±í™”
            )
            print(f"âœ… í•™ìŠµ ì™„ë£Œ: {model_path}")
        except Exception as e:
            import traceback
            error_msg = f"í•™ìŠµ ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}"
            print(f"âŒ {error_msg}")
            traceback.print_exc()
            return jsonify({'error': error_msg}), 500
        
        # ìµœì¢… í‰ê°€
        try:
            final_match_rate = trainer.evaluate()
            print(f"ğŸ“Š ìµœì¢… ì¼ì¹˜ìœ¨: {final_match_rate:.2%}")
        except Exception as e:
            print(f"âš ï¸  í‰ê°€ ì‹¤íŒ¨: {e}")
            final_match_rate = 0.0
        
        return jsonify({
            'status': 'success',
            'model_path': model_path,
            'final_match_rate': float(final_match_rate),
            'epochs': epochs
        })
    
    except Exception as e:
        import traceback
        error_msg = f"ì„œë²„ ì˜¤ë¥˜: {str(e)}"
        print(f"âŒ {error_msg}")
        traceback.print_exc()
        return jsonify({'error': error_msg}), 500


@app.route('/api/train/ppo', methods=['POST'])
def train_ppo_api():
    """
    PPO ê°•í™”í•™ìŠµ ì‹œì‘
    
    ìš”ì²­:
    - model_path: ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ ê²½ë¡œ (ì„ íƒ)
    - env_type: í™˜ê²½ íƒ€ì… (carracing/sim)
    - total_steps: ì´ í•™ìŠµ ìŠ¤í… ìˆ˜
    - ...
    
    ì‘ë‹µ:
    - status: success
    - model_path: í•™ìŠµëœ ëª¨ë¸ ê²½ë¡œ
    """
    try:
        data = request.json
        # TODO: PPO í•™ìŠµ ë¡œì§ êµ¬í˜„
        return jsonify({
            'status': 'success',
            'message': 'PPO training started (async)'
        })
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/model/latest', methods=['GET'])
def get_latest_model():
    """
    ìµœì‹  ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
    
    ì‘ë‹µ:
    - ëª¨ë¸ íŒŒì¼ (.pth)
    """
    try:
        # MODEL_FOLDERì—ì„œ ìµœì‹  ëª¨ë¸ ì°¾ê¸°
        model_files = [f for f in os.listdir(MODEL_FOLDER) if f.endswith('.pth')]
        if not model_files:
            return jsonify({'error': 'No model found'}), 404
        
        # ìµœì‹  íŒŒì¼ ì„ íƒ (ì´ë¦„ ê¸°ì¤€)
        latest_model = sorted(model_files)[-1]
        model_path = os.path.join(MODEL_FOLDER, latest_model)
        
        return send_file(
            model_path,
            as_attachment=True,
            download_name=latest_model
        )
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/model/list', methods=['GET'])
def list_models():
    """
    ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ
    
    ì‘ë‹µ:
    - models: ëª¨ë¸ íŒŒì¼ ëª©ë¡
    """
    try:
        model_files = [f for f in os.listdir(MODEL_FOLDER) if f.endswith('.pth')]
        model_info = []
        
        for model_file in sorted(model_files, reverse=True):
            model_path = os.path.join(MODEL_FOLDER, model_file)
            stat = os.stat(model_path)
            model_info.append({
                'filename': model_file,
                'size': stat.st_size,
                'modified': datetime.fromtimestamp(stat.st_mtime).isoformat()
            })
        
        return jsonify({
            'models': model_info
        })
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/inference', methods=['POST'])
def inference():
    """
    ì‹¤ì‹œê°„ ì¶”ë¡  (ì„ íƒ ì‚¬í•­)
    
    ìš”ì²­:
    - state: 256ì°¨ì› ìƒíƒœ ë²¡í„° (16x16 ì´ë¯¸ì§€)
    - model_path: ì‚¬ìš©í•  ëª¨ë¸ ê²½ë¡œ (ì„ íƒ, ê¸°ë³¸: ìµœì‹  ëª¨ë¸)
    
    ì‘ë‹µ:
    - action: ì¶”ë¡ ëœ ì•¡ì…˜ (0-4)
    - log_prob: ë¡œê·¸ í™•ë¥ 
    - value: ìƒíƒœ ê°€ì¹˜
    """
    try:
        data = request.json
        state = data.get('state')
        model_path = data.get('model_path')
        
        if state is None:
            return jsonify({'error': 'No state provided'}), 400
        
        # ëª¨ë¸ ë¡œë“œ
        if model_path is None:
            # ìµœì‹  ëª¨ë¸ ì‚¬ìš©
            model_files = [f for f in os.listdir(MODEL_FOLDER) if f.endswith('.pth')]
            if not model_files:
                return jsonify({'error': 'No model found'}), 404
            model_path = os.path.join(MODEL_FOLDER, sorted(model_files)[-1])
        
        # ì—ì´ì „íŠ¸ ë¡œë“œ ë° ì¶”ë¡ 
        agent = PPOAgent(
            state_dim=256,
            action_dim=5,
            discrete_action=True
        )
        agent.load(model_path)
        
        # ì¶”ë¡  (recurrent ê°’ ìŠ¹ê³„ë¥¼ ìœ„í•´ get_action_with_carry ì‚¬ìš©)
        state_tensor = torch.FloatTensor(state).unsqueeze(0)
        if hasattr(agent, 'use_recurrent') and agent.use_recurrent:
            action, log_prob, value, _ = agent.get_action_with_carry(
                state_tensor, deterministic=True
            )
        else:
            action, log_prob, value = agent.actor_critic.get_action(state_tensor)
        
        return jsonify({
            'action': int(action.item()),
            'log_prob': float(log_prob.item()),
            'value': float(value.item())
        })
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500


def main():
    parser = argparse.ArgumentParser(description='RC Car í•™ìŠµ ì„œë²„ API')
    parser.add_argument('--host', type=str, default='0.0.0.0',
                        help='ì„œë²„ í˜¸ìŠ¤íŠ¸ (ê¸°ë³¸: 0.0.0.0)')
    parser.add_argument('--port', type=int, default=5000,
                        help='ì„œë²„ í¬íŠ¸ (ê¸°ë³¸: 5000)')
    parser.add_argument('--debug', action='store_true',
                        help='ë””ë²„ê·¸ ëª¨ë“œ')
    
    args = parser.parse_args()
    
    print(f"ğŸš€ ì„œë²„ ì‹œì‘: http://{args.host}:{args.port}")
    print(f"ğŸ“ ì—…ë¡œë“œ í´ë”: {UPLOAD_FOLDER}")
    print(f"ğŸ“ ëª¨ë¸ í´ë”: {MODEL_FOLDER}")
    
    app.run(host=args.host, port=args.port, debug=args.debug)


if __name__ == '__main__':
    main()

